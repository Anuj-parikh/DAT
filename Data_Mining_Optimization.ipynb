{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_data = pd.read_csv('F:/Rahul Subjects/Data Mining/nba_logreg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>...</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brandon Ingram</td>\n",
       "      <td>36</td>\n",
       "      <td>27.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>34.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>69.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andrew Harrison</td>\n",
       "      <td>35</td>\n",
       "      <td>26.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JaKarr Sampson</td>\n",
       "      <td>74</td>\n",
       "      <td>15.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>42.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malik Sealy</td>\n",
       "      <td>58</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>42.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>68.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Geiger</td>\n",
       "      <td>48</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9</td>\n",
       "      <td>67.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name  GP   MIN  PTS  FGM  FGA   FG%  3P Made  3PA   3P%  ...  \\\n",
       "0   Brandon Ingram  36  27.4  7.4  2.6  7.6  34.7      0.5  2.1  25.0  ...   \n",
       "1  Andrew Harrison  35  26.9  7.2  2.0  6.7  29.6      0.7  2.8  23.5  ...   \n",
       "2   JaKarr Sampson  74  15.3  5.2  2.0  4.7  42.2      0.4  1.7  24.4  ...   \n",
       "3      Malik Sealy  58  11.6  5.7  2.3  5.5  42.6      0.1  0.5  22.6  ...   \n",
       "4      Matt Geiger  48  11.5  4.5  1.6  3.0  52.4      0.0  0.1   0.0  ...   \n",
       "\n",
       "   FTA   FT%  OREB  DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "0  2.3  69.9   0.7   3.4  4.1  1.9  0.4  0.4  1.3          0.0  \n",
       "1  3.4  76.5   0.5   2.0  2.4  3.7  1.1  0.5  1.6          0.0  \n",
       "2  1.3  67.0   0.5   1.7  2.2  1.0  0.5  0.3  1.0          0.0  \n",
       "3  1.3  68.9   1.0   0.9  1.9  0.8  0.6  0.1  1.0          1.0  \n",
       "4  1.9  67.4   1.0   1.5  2.5  0.3  0.3  0.4  0.8          1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name            0\n",
       "GP              0\n",
       "MIN             0\n",
       "PTS             0\n",
       "FGM             0\n",
       "FGA             0\n",
       "FG%             0\n",
       "3P Made         0\n",
       "3PA             0\n",
       "3P%            11\n",
       "FTM             0\n",
       "FTA             0\n",
       "FT%             0\n",
       "OREB            0\n",
       "DREB            0\n",
       "REB             0\n",
       "AST             0\n",
       "STL             0\n",
       "BLK             0\n",
       "TOV             0\n",
       "TARGET_5Yrs     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>...</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Ken Johnson</td>\n",
       "      <td>64</td>\n",
       "      <td>12.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>52.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>43.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Ken Johnson</td>\n",
       "      <td>64</td>\n",
       "      <td>12.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>52.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>43.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Pete Williams</td>\n",
       "      <td>53</td>\n",
       "      <td>10.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>60.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>42.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Melvin Turpin</td>\n",
       "      <td>79</td>\n",
       "      <td>24.7</td>\n",
       "      <td>10.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>51.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>78.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>Jim Petersen</td>\n",
       "      <td>60</td>\n",
       "      <td>11.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>48.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>75.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Tom Scheffler</td>\n",
       "      <td>39</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>41.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>Sam Williams</td>\n",
       "      <td>59</td>\n",
       "      <td>18.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>55.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>55.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>Kurt Nimphius</td>\n",
       "      <td>63</td>\n",
       "      <td>17.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>58.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>Pete Verhoeven</td>\n",
       "      <td>71</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>50.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>Jim Smith</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>50.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>Jeff Wilkins</td>\n",
       "      <td>56</td>\n",
       "      <td>18.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>67.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name  GP   MIN   PTS  FGM  FGA   FG%  3P Made  3PA  3P%  ...  \\\n",
       "338     Ken Johnson  64  12.7   4.1  1.8  3.3  52.8      0.0  0.0  NaN  ...   \n",
       "339     Ken Johnson  64  12.7   4.1  1.8  3.3  52.8      0.0  0.0  NaN  ...   \n",
       "340   Pete Williams  53  10.8   2.8  1.3  2.1  60.4      0.0  0.0  NaN  ...   \n",
       "358   Melvin Turpin  79  24.7  10.6  4.6  9.0  51.1      0.0  0.0  NaN  ...   \n",
       "386    Jim Petersen  60  11.9   3.2  1.2  2.4  48.6      0.0  0.0  NaN  ...   \n",
       "397   Tom Scheffler  39   6.9   1.3  0.5  1.3  41.2      0.0  0.0  NaN  ...   \n",
       "507    Sam Williams  59  18.2   6.1  2.6  4.7  55.6      0.0  0.0  NaN  ...   \n",
       "509   Kurt Nimphius  63  17.2   5.3  2.2  4.7  46.1      0.0  0.0  NaN  ...   \n",
       "510  Pete Verhoeven  71  17.0   4.9  2.1  4.2  50.3      0.0  0.0  NaN  ...   \n",
       "521       Jim Smith  72  11.9   2.9  1.2  2.3  50.9      0.0  0.0  NaN  ...   \n",
       "559    Jeff Wilkins  56  18.9   4.7  2.1  4.6  45.0      0.0  0.0  NaN  ...   \n",
       "\n",
       "     FTA   FT%  OREB  DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "338  1.3  43.5   1.4   2.4  3.8  0.3  0.2  0.3  0.9          0.0  \n",
       "339  1.3  43.5   1.4   2.4  3.8  0.3  0.2  0.3  0.9          0.0  \n",
       "340  0.8  42.5   0.9   1.9  2.8  0.3  0.4  0.4  0.4          0.0  \n",
       "358  1.8  78.4   2.0   3.8  5.7  0.5  0.5  1.1  1.5          1.0  \n",
       "386  1.1  75.8   0.7   1.7  2.5  0.5  0.2  0.5  1.2          1.0  \n",
       "397  0.5  50.0   0.5   1.5  1.9  0.3  0.2  0.3  0.4          0.0  \n",
       "507  1.5  55.1   1.5   3.7  5.2  0.6  0.8  1.3  1.1          0.0  \n",
       "509  1.7  58.3   1.5   3.2  4.7  1.0  0.3  1.3  0.9          1.0  \n",
       "510  1.0  70.8   1.5   2.1  3.6  0.7  0.6  0.3  0.8          1.0  \n",
       "521  1.2  45.9   1.0   1.5  2.5  0.6  0.3  0.7  0.7          0.0  \n",
       "559  0.7  67.5   1.1   3.8  4.9  0.7  0.6  0.8  1.1          1.0  \n",
       "\n",
       "[11 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_data[nba_data.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3P% = (3P Made/3PA)*100\n",
    "### FG% = (FGM/FGA)*100\n",
    "### FT% = (FTM/FTA)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_data = nba_data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is because the 3P% is calculated from 3P Made and 3PA. And we can see from the above table that both 3P Made and 3PA are 0's so it is better to fill the 3P% with 0 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = nba_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1340, 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1328, 21)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "print( df.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There were twelve duplicates and we dropped them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASgAAAE9CAYAAAC4HP8xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAANIElEQVR4nO3dcWycdR3H8c93O6bDoshGcCnoJCUSDYpsIRATPSYkAwb84UyY4DaJkEjsJsEEA4krJizZH5BgjSEsLjJZBsk0ZpvdlGUs/qPEKxkOwiQnhrgxdXRmMLeA3X7+cde5dr326d1zvc/d3q9kSZ/rj+f5/fZ0b353126RUhIAOJrR6gkAQC0ECoAtAgXAFoECYItAAbBFoADYKkxl8Ny5c9P8+fObNBUA56rBwcF3UkoXj318SoGaP3++SqVSfrMCAEkR8dZ4j/MUD4AtAgXAFoECYItAAbBFoADYIlAAbBEoALYIFABbBAqALQIFwBaBAmCLQAGwRaAA2CJQAGwRKAC2CBQAWwQKgC0CBcAWgQJgi0ABsEWgANgiUABsESgAtggUAFtT+oc720V/f7/K5XJu5zt48KAkqbu7O7dzTkVPT496e3tbcm2glToyUOVyWXtffV0nz78ol/PNPH5UkvSP96f/t2vm8SPTfk3ARUcGSpJOnn+RTlx5Sy7nmr1/QJJyO1891wbORbwGBcAWgQJgi0ABsEWgANgiUABsESgAtggUAFsECoAtAgXAFoECYItAAbBFoADYIlAAbBEoALYIFABbBAqALQIFwBaBAmCLQAGwRaAA2CJQAGwRKAC2CBQAWwQKgC0CBcAWgQJgi0ABsEWgANgiUABsESgAtggUAFsECoAtAgXAFoECYItAAbBFoADYIlAAbBEoALYIFABbBAqALQIFwBaBAmCLQAGwRaAA2CJQAGwRKAC2CBQAWwQKgC0CBcAWgQJgi0ABsEWgANhqWqD6+/vV39/frNMDfI2dAwrNOnG5XG7WqQFJfI2dC3iKB8AWgQJgi0ABsEWgANgiUABsESgAtggUAFsECoAtAgXAFoECYItAAbBFoADYIlAAbBEoALYIFABbBAqALQIFwBaBAmCLQAGwRaAA2CJQAGwRKAC2CBQAWwQKgC0CBcAWgQJgi0ABsEWgANgiUABsESgAtggUAFsECoAtAgXAFoECYItAAbBFoADYIlAAbBEoALYIFABbBAqALQIFwBaBAmCLQAGwRaAA2CJQAGwRKAC2CBQAWwQKgC0CBcAWgULHW7ZsmYrFou6+++4Jx61bt07FYlGPP/54LuPWr1+vYrGoDRs2TDhu9+7dKhaLevHFF3MZJ0lDQ0NatWqVhoaGpnVcqVTSokWLNDg4OOkcsyBQ6HiHDh2SJB04cGDCcTt27JAkbdu2LZdxmzZtkiRt3LhxwnFr166VJD322GO5jJOkZ555Rvv27Zv02nmP6+vr06lTp7RmzZpJ55gFgUJHW7Zs2ajjWruodevWjTqutTvKOm79+vWjjmvtonbv3q3h4WFJ0vDwcM3dUdZxUmW3s3PnTqWUtHPnzpq7nrzHlUolHTt2TJJ07NixXHZRkVLKPHjhwoWpVCplGrt06VKdOHFCPT099c6tbuVyWe99kPSfq+/M5Xyz9w9Ikk5ceUsu55uKj+x9ThfMipb8Prorl8uaPXu2tmzZUnNMsVg867E9e/bYjLvxxhtPh0eSCoWCdu3aVfc4SXriiSc0MDCg4eFhFQoF3XrrrXrggQeaPm7JkiWnAyVJXV1d2r59+7hzHCsiBlNKC8c+PukOKiLui4hSRJQOHz6c6WIAsjkzOuMdT3WcJO3atWvUbuuFF16YlnFnxmm843oUJhuQUnpa0tNSZQeV9cTd3d2SpCeffLLeudVt9erVGnzzn9N+3WY49eGPqufyS1ry++hu9erVrZ5CwwqFwlk7o0bGSZXd1pk7nptuumlaxnV1dZ21g2oUr0Gho82bN2/U8aWXXjruuJtvvnnU8W233dbQuLvuumvU8fLly8cd9/DDD486fuSRRxoaJ0krVqzQjBmVP9ozZ86see28x/X19Y06fvTRR2vOMSsChY62efPmUcfPPvvsuOMeeuihUccPPvhgQ+PuvffeUcf33HPPuOMWLVp0ejdUKBR0ww03NDROkubMmaPFixcrIrR48WLNmTNnWsYtXLjw9K6pq6tLCxYsqDnHrAgUOt7ILqrW7mnEyO6o1q5oquNGdlG1dhwjRnZHE+2KpjJOqux6rrrqqkmvnfe4vr4+zZgxI5fdk9TEd/FGXh9o5WtQeb3r1sp38WbvH9ACXoMaVyu/xpCvut/FA4BWIVAAbBEoALYIFABbBAqALQIFwBaBAmCLQAGwRaAA2CJQAGwRKAC2CBQAWwQKgC0CBcAWgQJgi0ABsEWgANgiUABsESgAtggUAFsECoAtAgXAFoECYItAAbBFoADYIlAAbBEoALYIFABbBAqALQIFwBaBAmCLQAGwRaAA2CJQAGwRKAC2CBQAWwQKgC0CBcAWgQJgi0ABsEWgANgiUABsESgAtggUAFsECoAtAgXAFoECYItAAbBVaNaJe3p6mnVqQBJfY+eCpgWqt7e3WacGJPE1di7gKR4AWwQKgC0CBcAWgQJgi0ABsEWgANgiUABsESgAtggUAFsECoAtAgXAFoECYItAAbBFoADYIlAAbBEoALYIFABbBAqALQIFwBaBAmCLQAGwRaAA2CJQAGwRKAC2CBQAWwQKgC0CBcAWgQJgi0ABsEWgANgiUABsESgAtggUAFsECoAtAgXAFoECYItAAbBFoADYIlAAbBEoALYIFABbBAqALQIFwBaBAmCLQAGwRaAA2CJQAGwRKAC2CBQAWwQKgC0CBcAWgQJgq9DqCTTLzONHNHv/QE7nGpKk3M43tWsfkXTJtF8XcNCRgerp6cn1fAcPDkuSurtbEYpLcl8P0C46MlC9vb2tngKAHPAaFABbBAqALQIFwBaBAmCLQAGwRaAA2CJQAGwRKAC2CBQAWwQKgC0CBcAWgQJgi0ABsEWgANgiUABsESgAtggUAFsECoAtAgXAFoECYItAAbBFoADYIlAAbBEoALYIFABbkVLKPjjisKS3pnD+uZLemeqkTLEWT52ylk5Zh1TfWj6VUrp47INTCtRURUQppbSwaReYRqzFU6espVPWIeW7Fp7iAbBFoADYanagnm7y+acTa/HUKWvplHVIOa6lqa9BAUAjeIoHwFYugYqIxRHxl4goR8QPxvn8hyLi+ernX4qI+XlctxkyrGVlRByOiL3VX99uxTwnExEbIuJfEfFqjc9HRPy4us4/R8Q10z3HrDKspRgRR8+4Jz+c7jlmERGXRcSLEfF6RLwWEavHGdMW9yXjWhq/Lymlhn5Jminpr5IulzRL0iuSPjtmzP2Snqp+fKek5xu9bjN+ZVzLSkk/afVcM6zly5KukfRqjc/fImmHpJB0naSXWj3nBtZSlLS91fPMsI55kq6pfnyBpDfG+fpqi/uScS0N35c8dlDXSiqnlN5MKX0g6TlJd4wZc4ekZ6ofb5H01YiIHK6dtyxraQsppd9LOjLBkDskbUwVf5R0YUTMm57ZTU2GtbSFlNKhlNLL1Y/fk/S6pO4xw9rivmRcS8PyCFS3pL+fcXxAZ0/09JiU0rCko5Lm5HDtvGVZiyR9rbr93hIRl03P1HKXda3t4vqIeCUidkTE51o9mclUX+b4oqSXxnyq7e7LBGuRGrwveQRqvJ3Q2LcGs4xxkGWe2yTNTyl9XtIu/X9n2G7a5Z5k8bIqPyrxBUn9kn7d4vlMKCK6JP1S0vdSSu+O/fQ4/4ntfZlkLQ3flzwCdUDSmbuISyW9XWtMRBQkfUyeW/ZJ15JSGkopvV89XC9pwTTNLW9Z7ltbSCm9m1I6Vv14QNJ5ETG3xdMaV0Scp8of6E0ppV+NM6Rt7stka8njvuQRqD9JuiIiPh0Rs1R5EXzrmDFbJa2ofrxU0u5UfRXNzKRrGfN6wO2qPPduR1slLa++a3SdpKMppUOtnlQ9IuITI69pRsS1qnxdD7V2VmerzvFnkl5PKT1RY1hb3Jcsa8njvhQanWhKaTgivivpt6q8C7YhpfRaRPxIUimltFWVhfwiIsqq7JzubPS6zZBxLasi4nZJw6qsZWXLJjyBiNisyrsocyPigKQ1ks6TpJTSU5IGVHnHqCzpuKRvtWamk8uwlqWSvhMRw5JOSLrT9H+AX5L0TUn7ImJv9bGHJX1Sarv7kmUtDd8XvpMcgC2+kxyALQIFwBaBAmCLQAGwRaAA2Gr42wxw7oqIRyR9Q9JJSack/VvSxyV1SbpY0t+qQ++XtFbS91NKpRZMFW2KQKEuEXG9pCWq/ET7+9XvEJ6VUno7IoqqxGjJGeNbNFO0MwKFes2T9M7Ij/2klDrln0yCEV6DQr1+J+myiHgjIn4aEV9p9YTQeQgU6lL9IdAFku6TdFjS8xGxsqWTQsfhKR7qllI6KWmPpD0RsU+VHwj/eSvnhM7CDgp1iYjPRMQVZzx0taS3WjUfdCZ2UKhXl6T+iLhQlb/ZoazK072J/CYi/lv9+A8ppa83c4Jof/xtBgBs8RQPgC0CBcAWgQJgi0ABsEWgANgiUABsESgAtggUAFv/A7L9z8vnTZA1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASoAAAE9CAYAAAC86S8MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAPfUlEQVR4nO3df4zcdV7H8de7XZAey92FFvGyXFzJGhuVE+mG1NPoUEtsWgIJVxIMhlYU04htxTSK0BytKcgfpB5dyRF6x0G1Zy/00GDTq6G2xH8s55YrBxeqmbv0IhWltyh3hebObT/+MTPL/Nz9zuz3u/Pa+nwkTWa/vz6f/cI85zvf6W4jpSQAcLag3xMAgJkQKgD2CBUAe4QKgD1CBcAeoQJgb6CbjZcsWZKGh4cLmgqA/6+OHz/+vZTSVZ3WdxWq4eFhjY+Pz35WAFAnIr473Xre+gGwR6gA2CNUAOwRKgD2CBUAe4QKgD1CBcAeoQJgj1ABsEeoANgjVADsESoA9ggVAHuECoA9QgXAHqECYI9QAbBHqADYI1QA7BEqAPYIFQB7hAqAPUIFwB6hAmCvq3+ANC9jY2Mql8sty0+fPi1JGhoaym2skZERbdy4MbfjAZh7fQlVuVzWiTfe1PmPXNmwfOEH70mS/vOH+Uxr4Qfv5nIcAP3Vl1BJ0vmPXKlzS1c3LFt08qAktSzvVe14AOY37lEBsEeoANgjVADsESoA9ggVAHuECoA9QgXAHqECYI9QAbBHqADYI1QA7BEqAPYIFQB7hAqAPUIFwB6hAmCPUAGwR6gA2CNUAOwRKgD2CBUAe4QKgD1CBcAeoQJgj1ABsEeoANgjVADsESoA9ggVAHuECoA9QgXAHqECYI9QAbBHqADYI1QA7BEqAPYIFQB7hAqAPUIFwB6hAmCPUAGwR6gA2CNUAOwRKgD2CBUAe4QKgD1CBcAeoQJgj1ABsEeoANgjVADsESoA9goL1djYmMbGxoo6/LzH+QGyGyjqwOVyuahDXxQ4P0B2vPUDYI9QAbBHqADYI1QA7BEqAPYIFQB7hAqAPUIFwB6hAmCPUAGwR6gA2CNUAOwRKgD2CBUAe4QKgD1CBcAeoQJgj1ABsEeoANgjVADsESoA9ggVAHuECoA9QgXAHqECYI9QAbBHqADYI1QA7BEqAPYIFQB7hAqAPUIFwB6hAmCPUAGwR6gA2CNUAOwRKgD2CBUAe4QKgD1CBcAeoQJgj1ABsEeoANgjVADsESoA9ggVAHuECoA9QgXAHqECYI9Qmdm1a5dKpZKefPLJlnVbtmxRqVTSAw880LB8+/btKpVKeuSRRzLvs3fvXpVKJe3bt69lnyNHjqhUKuno0aMNy3fv3q1SqaRnnnmmZZ/x8XGtWLFCx48fz/R9TrdPuVzWmjVrVC6XMx9rYmJCmzZt0sTERC779HI8B53m3cs5zXP82SJUZl544QVJ0vPPP9+ybnx8XJJ07NixhuW1oLz00kuZ99m9e7ck6amnnmrZ59FHH5WklvDt3btXkrRnz56WfbZt26YLFy7o4YcfblnXSad9duzYoffff187duzIfKznnntOr7/+etu59bJPL8dz0GnevZzTPMefLUJlZNeuXQ1f119VbdmypWFd7Qpp+/btDcvr49Jpn1pwauqvqo4cOaLJyUlJ0uTk5FQEa2Grqb+qGh8f19mzZyVJZ8+ezXRV1WmfcrmsU6dOSZJOnTqV6QpgYmJChw4dUkpJhw4dyvRqPt0+vRzPQad593JO8xw/D5FSyrzx6Ohoqr1Cz2Tt2rU6d+6cRkZGWtaVy2X94EdJ719/Z8PyRScPSpLOLV2deU7TufzEPl1xabSdQ7+Vy2UtWrRI+/fvn1pWKpVatnv55ZenXZf3PitXrpwKlSQNDAzo8OHD0+5zyy23TEVHkgYHB3XgwIGW7et12mf9+vVTTypJGh4e1rPPPjvtsXbu3KmDBw9qcnJSAwMDWrNmje6///6e9+nleA46zbuXc5rn+FlExPGU0min9TNeUUXE70XEeESMnzlzpotpYz6qj1S7r9upD067r7vZp/4J1e7rdg4fPtxwFdjuLXA3+/RyPAed5t3LOc1z/DwMzLRBSulpSU9LlSuqrAceGhqSJD3xxBMt6zZv3qzj3/mvzJPs1YXLPqqRa69uO4d+27x5c7+n0NbAwEDLFdVMBgcHW66Oet1neHi45dV/JitXrmx4Jb/55ptntU8vx3PQad69nNM8x88D96iM3H777Q1f33HHHVOPR0cbr4qXL18uSbrpppsaltf/z9Fpn3vvvbdh+YYNG6YeP/jggw3rHnroIUnSXXfd1bD87rvvnnq8bdu2hnXN983a6bTP1q1bG5Y3f93OunXrtGBB5X/lhQsXNsytl316OZ6DTvPu5ZzmOX4eCJWRTZs2NXx93333TT1+/PHHG9Y99thjktTyiVktLNPt0xydO+/88F7hihUrpq6iBgYGpkLYHLd77rln6vHo6OjUFdHg4KCWLVvW9vur12mfkZGRqVf84eHhTPcXFy9erFWrVikitGrVKi1evHhW+/RyPAed5t3LOc1z/DwQKjO1q6r6q6ma2hVS7cqophaTdpfanfaphaf+aqqmdlVVHz3pw8C1e6Xctm2bFixYkOlqaqZ9tm7dqssvv7yrV/5169bpuuuu6+pVfLp9ejmeg07z7uWc5jn+bBX2qV/tHsx096iaP93L+1O/RScPapn5PSrHuQFzbdaf+gFAvxEqAPYIFQB7hAqAPUIFwB6hAmCPUAGwR6gA2CNUAOwRKgD2CBUAe4QKgD1CBcAeoQJgj1ABsEeoANgjVADsESoA9ggVAHuECoA9QgXAHqECYI9QAbBHqADYI1QA7BEqAPYIFQB7hAqAPUIFwB6hAmCPUAGwR6gA2CNUAOwRKgD2CBUAe4QKgD1CBcAeoQJgj1ABsEeoANgjVADsESoA9ggVAHuECoA9QgXAHqECYI9QAbBHqADYGyjqwCMjI0Ud+qLA+QGyKyxUGzduLOrQFwXOD5Adb/0A2CNUAOwRKgD2CBUAe4QKgD1CBcAeoQJgj1ABsEeoANgjVADsESoA9ggVAHuECoA9QgXAHqECYI9QAbBHqADYI1QA7BEqAPYIFQB7hAqAPUIFwB6hAmCPUAGwR6gA2CNUAOwRKgD2CBUAe4QKgD1CBcAeoQJgj1ABsEeoANgjVADsESoA9ggVAHuECoA9QgXAHqECYI9QAbBHqADYI1QA7BEqAPYIFQB7hAqAPUIFwB6hAmCPUAGwR6gA2CNUAOwRKgD2CBUAewP9GnjhB+9q0cmDTcsmJKll+WzGkK7O5VgA+qcvoRoZGWm7/PTpSUnS0FBecbm641gA5o++hGrjxo39GBbAPMU9KgD2CBUAe4QKgD1CBcAeoQJgj1ABsEeoANgjVADsESoA9ggVAHuECoA9QgXAHqECYI9QAbBHqADYI1QA7BEqAPYIFQB7hAqAPUIFwB6hAmCPUAGwR6gA2CNUAOwRKgD2IqWUfeOIM5K+28Xxl0j6XreTylm/59Dv8R3m0O/xHebQ7/Hd5/CTKaWrOu3UVai6FRHjKaXRwgaYB3Po9/gOc+j3+A5z6Pf4830OvPUDYI9QAbBXdKieLvj4WfR7Dv0eX+r/HPo9vtT/OfR7fGkez6HQe1QAkAfe+gGwl0uoImJVRPxrRJQj4oE2638sIr5SXf9KRAznMW6Xc1gfEWci4kT1z+/mPP4zEfFORLzRYX1ExK7q/L4ZETfM8filiHiv7vv/bM7jfzIijkbEmxHxrYjY3Gabos9BljkUdh4i4rKI+HpEvFYdf3ubbQp9LmScQ6HPheoYCyPiGxFxoM267s9BSmlWfyQtlPRtSddKulTSa5J+tmmb35f0VPXxnZK+Mttxe5jDekl/mee4Tcf/VUk3SHqjw/rVkr4mKSQtl/TKHI9fknSgwO//E5JuqD6+QtK/tflvUPQ5yDKHws5D9fsarD6+RNIrkpY3bVP0cyHLHAp9LlTH+CNJX253rns5B3lcUd0oqZxS+k5K6UeS9km6rWmb2yQ9V328X9KvR0TkMHY3cyhUSumfJL07zSa3SdqTKo5J+nhEfGIOxy9USuntlNKr1cc/kPSmpKGmzYo+B1nmUJjq93W2+uUl1T/NN4ELfS5knEOhIuIaSWskfaHDJl2fgzxCNSTp3+u+fkut/3NMbZNSmpT0nqTFOYzdzRwk6TPVtxz7I+KTOY6fRdY5FumXqm8JvhYRP1fUINVL+V9U5dW83pydg2nmIBV4HqpveU5IekfSSymljuegoOdCljlIxT4XPifpjyVd6LC+63OQR6jalbC54Fm2KXoOfy9pOKX0KUmH9WHR50rR52Amr6ryYwq/IGlM0t8VMUhEDEr6qqQ/TCl9v3l1m11yPwczzKHQ85BSOp9Sul7SNZJujIifb55eu93meA6FPRci4hZJ76SUjk+3WZtl056DPEL1lqT6Il8j6T86bRMRA5I+pnzfpsw4h5TSRErph9Uvd0taluP4WWQ5T4VJKX2/9pYgpXRQ0iURsSTPMSLiElUCsTel9EKbTQo/BzPNYS7OQ/XY/yPpZUmrmlYV/VyYcQ4FPxd+WdKtEXFKlVswKyLir5u26foc5BGqf5H00xHxUxFxqSo3x15s2uZFSeuqj9dKOpKqd9JyMuMcmu6F3KrK/Yu59KKku6uffC2X9F5K6e25GjwifqJ2HyAiblTlv/1EjscPSV+U9GZKaWeHzQo9B1nmUOR5iIirIuLj1ceLJK2UdLJps0KfC1nmUORzIaX0pymla1JKw6o8D4+klH6rabPuz0FOd/hXq/IJy7clPVRd9meSbq0+vkzS85LKkr4u6dq8Pl3oYg5/LulbqnwieFTS0pzH/xtJb0v6X1VeMX5H0gZJG9KHn8Y8WZ3f65JG53j8P6j7/o9J+nTO4/+KKpfv35R0ovpn9RyfgyxzKOw8SPqUpG9Ux39D0mfn+rmQcQ6FPhfq5lJS9VO/2Z4D/mY6AHv8zXQA9ggVAHuECoA9QgXAHqECYI9QoScRcb76k/evRcSrEfHp6vLhaPMbHCLi2YhYW318ZfUn6397rueN+Wmg3xPAvHUuVX5MQxHxG6r83Zxfm2mniPiYpH+Q9HRK6UvFThEXC66okIePSvrvDNsNqvJrXr6cUvp8sVPCxYQrKvRqUfUn9C9T5fdArciwz05JX0gp/UWhM8NFhysq9OpcSun6lNJSVX7odU+G36t0RNJtEfHjxU8PFxNChVlLKf2zKv8Cbsd/6bZqn6TPSzoYEVcUPjFcNAgVZi0ilqry66Bn/C0EKaXPSfpHSX9b/U0XwIy4R4Ve1e5RSZXfirAupXS++u7vZyLirbpt76/fMaX0JxHxJUl/FRG/mVLq9JsgAUn8u34A5gHe+gGwR6gA2CNUAOwRKgD2CBUAe4QKgD1CBcAeoQJg7/8AQwdzktzRx0sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    ax = sns.boxplot(x=df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From these set of graphs we take the graphs that have outstanding outliers and remove them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c93f5a5c88>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(df['PTS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352     28.2\n",
       "118     24.3\n",
       "442     23.7\n",
       "1157    23.5\n",
       "1308    23.4\n",
       "Name: PTS, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['PTS'].sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1327, 20)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['PTS'] <=25 ]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c93f371348>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(df['FG%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1109    73.7\n",
       "728     66.2\n",
       "692     66.1\n",
       "301     65.9\n",
       "761     63.3\n",
       "791     61.6\n",
       "500     61.3\n",
       "597     60.8\n",
       "340     60.4\n",
       "359     60.0\n",
       "Name: FG%, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FG%'].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1326, 20)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['FG%'] <=70 ]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c93f5ae5c8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAEGCAYAAABbzE8LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAOPUlEQVR4nO3df2jcdx3H8de7uUmzxiG2o850LMqJgg73IwylMNLYSGwW5z+io9uKsOofmrWrQ7QNNIF2/iGUjf4hbJ3SYXVIp9RIqXZLZSr44zJXu7mqh6TYzrkuQ13a7kfat3/cJeS+9017l93d+259PmCs9+33+/m+d3TPffPN5TtzdwEAGm9J9AAAcLkiwAAQhAADQBACDABBCDAABMlUs/OKFSu8q6urTqMAwDvTxMTEK+5+dXJ7VQHu6upSLper3VQAcBkwsxNp27kFAQBBCDAABCHAABCEAANAEAIMAEEIMAAEIcAAEIQAA0AQAgwAQQgwAAQhwAAQhAADQBACDABBCDAABCHAABCEAANAEAIMAEEIMAAEIcAAEKSq/yfcYu3evVv5fL7q406dOiVJ6uzsrPVINZXNZjU0NBQ9BoAW05AA5/N5PfvcCzp/5XurOq7t7H8lSS+90ZAxF6Xt7KvRIwBoUQ0r2/kr36tzH1lX1THtxw9KUtXHNdLsjABQLe4BA0AQAgwAQQgwAAQhwAAQhAADQBACDABBCDAABCHAABCEAANAEAIMAEEIMAAEIcAAEIQAA0AQAgwAQQgwAAQhwAAQhAADQBACDABBCDAABCHAABCEAANAEAIMAEEIMAAEIcAAEIQAA0AQAgwAQQgwAAQhwAAQhAADQBACDABBCDAABCHAABCEAANAEAIMAEEIMAAEIcAAEIQAA0AQAgwAQQgwAAQhwAAQhAADQJBMI05y6tQpLXn9bCNOhRa0e/duSdLQ0FDwJEBjNSTA586dk114qxGnQgvK5/PRIwAhuAUBAEEIMAAEIcAAEIQAA0AQAgwAQQgwAAQhwAAQhAADQBACDABBCDAABCHAABCEAANAEAIMAEEIMAAEIcAAEIQAA0AQAgwAQQgwAAQhwAAQhAADQBACDABBCDAABCHAABCEAANAEAIMAEEIMAAEIcAAEIQAA0AQAgwAQQgwAAQhwAAQhAADQBACDABBCDAABCHAABCEAANAEAIMAEEIMAAEIcBoOuPj4+rp6dGRI0cuui2fz2tgYED5fF6SdODAAfX09GhsbGxun9HRUfX09Gjnzp1z23K5nHp7ezUxMbHg2mlrpe2XXCs500JrJfdLW3tqakr33nuvpqamFjwuef6Fjkvul7ZPmkr3i5Y2Z61mr+d7QIDRdB544AFJKolm2rYdO3bozJkz2rFjhyTpwQcflCTt2rVrbp/ZoB0+fHhu28jIiC5cuKDt27cvuHbaWmn7JddKzrTQWsn90tbeu3evjh07pscee2zB45LnX+i45H5p+6SpdL9oaXPWavZ6vgcEGE1lfHxcMzMzkqSZmRkdOXIkdVs+n9fk5KQkaXJyUo888ojcXZLk7hobG9Po6GjJ2jt37lQul9P09LQkaXp6Wnv27Clb+8CBA2Vrpc2QXGtsbKxkpnw+n7pWcvZ9+/aVrT01NaVDhw7J3XXo0CFNTU2VHTc2NlZy/omJidTjknOOj4+X7ZMmba1mlDZnrWav93tgs384KtHd3e25XK7qkwwMDGj69Tc1fdNdVR3XfvygJOncR9ZVfc5GWfbs43r3u0zZbDZ6lJaVz+fV3t6u/fv3a+3atXMxkqRMJiNJZdtWrVo1F6M0Zqa0P9sdHR1zMUqTyWR0/vz5kmPNTG1tbWUzLF26tGSt5Dm7urp04sSJsrWuu+66i86eyWS0bt06HTx4UDMzM8pkMhoYGNDRo0dLjkuer6OjQ729vWXHPfXUUyVzzn9PZ/e57777yubYtWtX2Vpp+0VLm9PdazJ7rd4DM5tw9+7k9kteAZvZl80sZ2a506dPV31ioBrzIzf7Om3bxQImKTW+ki4a39m1k8e6e+oMybWSx01OTqaudanZZ2Zm9OSTT5ZcFR8+fLjsuOTa09PTqccl55z/ns7ukyZtrWaUNmetZq/3e5C51A7u/rCkh6XCFXBNz/4OcGHpVcp+cKUeeuih6FFa1qZNm+Z+nclkuALOZLR27dqSK6++vr5FXQH39fVd8gq4r68vdY60GZpR2pzJK+DFzl7v94B7wGgqW7duLXm9bdu21G3Dw8Ml29avX1/yesuWLVqzZk3Jtr6+Po2MjJRsu/POO8vW3rx5c9laaTMk19qyZUvJ6+Hh4dS1krNv3LixbO0NGzZoyZLCv55tbW26++67y45Lnm90dDT1uOScW7duLdsnTdpazShtzlrNXu/3gACjqfT29s5doWUyGa1ZsyZ1WzabVVdXl6TClebGjRtlZpIKV4aDg4MlnwyQCmHr7u5WR0eHpMIV4z333FO29u233162VtoMybUGBwdLZspms6lrJWdfv3592drLly9Xf3+/zEz9/f1avnx52XGDg4Ml57/55ptTj0vO2dvbW7ZPmrS1mlHanLWavd7vAQFG05m92ty2bdtFtw0PD2vZsmVzV4azV5vzrwxnr4Lnf+k4MjKiJUuWzH1KIm3ttLXS9kuulZxpobWS+6WtvWHDBl1//fUlV13J45LnX+i45H5p+6SpdL9oaXPWavZ6vgd8CuJtaj9+UDdzD/htmb0HzHuId6pFfwoCAFAfBBgAghBgAAhCgAEgCAEGgCAEGACCEGAACEKAASAIAQaAIAQYAIIQYAAIQoABIAgBBoAgBBgAghBgAAhCgAEgCAEGgCAEGACCEGAACEKAASAIAQaAIAQYAIIQYAAIQoABIAgBBoAgBBgAghBgAAhCgAEgCAEGgCAEGACCEGAACEKAASAIAQaAIAQYAIIQYAAIQoABIAgBBoAgBBgAgmQacZL29na99qY34lRoQdlsNnoEIERDAtzZ2amX3vh3I06FFjQ0NBQ9AhCCWxAAEIQAA0AQAgwAQQgwAAQhwAAQhAADQBACDABBCDAABCHAABCEAANAEAIMAEEIMAAEIcAAEIQAA0AQAgwAQQgwAAQhwAAQhAADQBACDABBCDAABCHAABCEAANAEAIMAEEIMAAEIcAAEIQAA0AQAgwAQQgwAAQhwAAQhAADQBACDABBCDAABCHAABCEAANAEAIMAEEIMAAEIcAAEIQAA0AQAgwAQQgwAATJNOpEbWdfVfvxg1UeMyVJVR/XSG1nX5W0MnoMAC2oIQHOZrOLOu7UqRlJUmdnMwdu5aL/+QBc3hoS4KGhoUacBgBaCveAASAIAQaAIAQYAIIQYAAIQoABIAgBBoAgBBgAghBgAAhCgAEgCAEGgCAEGACCEGAACEKAASAIAQaAIAQYAIIQYAAIQoABIAgBBoAgBBgAghBgAAhi7l75zmanJZ1Y5LlWSHplkcdGY/bGa9W5JWaP0syzX+fuVyc3VhXgt8PMcu7e3ZCT1RizN16rzi0xe5RWnJ1bEAAQhAADQJBGBvjhBp6r1pi98Vp1bonZo7Tc7A27BwwAKMUtCAAIQoABIEjdA2xm/Wb2VzPLm9k3632+WjKz75nZy2b2XPQs1TCza83siJm9YGbPm9mm6JkqZWZLzewPZna0OPto9EzVMrM2M/uTmf08epZqmNmkmR0zs2fNLBc9T6XM7D1mtt/Mjhf/zH8yeqZK1fUesJm1SfqbpD5JJyX9UdId7v6Xup20hszsVknTkh5z949Fz1MpM7tG0jXu/oyZvVvShKTPtcL7bmYmaZm7T5vZFZJ+I2mTu/8ueLSKmdkWSd2SrnL326LnqZSZTUrqdvdm/WGGVGa2V9Kv3X2Pmb1L0pXu/p/ouSpR7yvgWyTl3f0f7v6mpMcl3V7nc9aMuz8t6dXoOarl7v9y92eKv35N0guSOmOnqowXTBdfXlH8q2W+U2xmqyQNSNoTPcvlwMyuknSrpEclyd3fbJX4SvUPcKekf857fVItEoJ3CjPrknSjpN/HTlK54pfwz0p6WdJhd2+Z2SU9KOkbki5ED7IILumXZjZhZl+OHqZCH5R0WtL3i7d99pjZsuihKlXvAFvKtpa5mml1ZtYh6QlJm939f9HzVMrdz7v7DZJWSbrFzFri9o+Z3SbpZXefiJ5lkVa7+02SPiPpq8VbcM0uI+kmSd919xslnZHUMt9rqneAT0q6dt7rVZJerPM5Ial4//QJSfvc/SfR8yxG8UvJX0nqDx6lUqslfbZ4L/VxSb1m9oPYkSrn7i8W//6ypJ+qcAux2Z2UdHLeV0n7VQhyS6h3gP8o6UNm9oHizfEvSvpZnc952St+I+tRSS+4+67oeaphZleb2XuKv26XtFbS8dipKuPu33L3Ve7epcKf9XF3vzN4rIqY2bLiN2xV/BL+05Ka/tM/7v6SpH+a2YeLmz4lqem/2TwrU8/F3X3GzL4m6ReS2iR9z92fr+c5a8nMfiSpR9IKMzspabu7Pxo7VUVWS7pL0rHivVRJ2uruBwNnqtQ1kvYWP0GzRNKP3b2lPs7VolZK+mnhv93KSPqhux+KHaliQ5L2FS/y/iHpS8HzVIwfRQaAIPwkHAAEIcAAEIQAA0AQAgwAQQgwAAQhwGh6Cz0hzcx+VXzS3lEz++28z4LOfp74LTP7StzkwMURYLSCNyT1uvvHJd0gqd/MPlH8vfXF7XslfWfeMZ+X9DtJdzR0UqAKBBhNr8InpD0tKTvv9R2Svi5plZnxACg0JQKMllDBE9IGJR0r7nutpPe5+x8k/VjSFxo6LFAhAoyWcJEnpO0rhnm1pPuL276oQnilwkNxuA2BpsSPIqPlmNl2FR47eJuk+909l/j9Z1R4tsFbxU3vl/RRd/97QwcFLoErYDS9ap6QVvwkxDJ373T3ruKTyb6twlUx0FQIMFrBNZKOmNmfVXjE6eGLPCHtDhWeZTvfE+I2BJoQtyAAIAhXwAAQhAADQBACDABBCDAABCHAABCEAANAEAIMAEH+D2WxH0fma9GRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(df['3PA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1087    6.5\n",
       "585     6.1\n",
       "1157    6.0\n",
       "1158    5.1\n",
       "922     4.9\n",
       "1190    4.8\n",
       "172     4.8\n",
       "698     4.8\n",
       "699     4.7\n",
       "1164    4.6\n",
       "Name: 3PA, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['3PA'].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1323, 20)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['3PA'] <=5.5 ]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c93f5508c8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(df['3P%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1253    100.0\n",
       "1174    100.0\n",
       "45      100.0\n",
       "1053    100.0\n",
       "528      66.7\n",
       "Name: 3P%, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['3P%'].sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1319, 20)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['3P%'] <=80 ]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c93cfbc2c8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(df['FTM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118     7.5\n",
       "1312    6.3\n",
       "490     6.0\n",
       "1310    5.7\n",
       "1192    5.4\n",
       "Name: FTM, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FTM'].sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1318, 20)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['FTM'] <=7.0 ]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c93eed6d88>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(df['FT%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "809     0.0\n",
       "12     28.6\n",
       "887    29.6\n",
       "441    31.3\n",
       "485    31.3\n",
       "Name: FT%, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FT%'].sort_values(ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1317, 20)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['FT%'] >=20.0 ]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c93e713688>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(df['OREB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538     5.3\n",
       "442     4.3\n",
       "1055    4.3\n",
       "443     4.2\n",
       "491     4.2\n",
       "Name: OREB, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['OREB'].sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1316, 20)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['OREB'] <=5.0 ]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c93f5294c8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(df['REB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1308    13.9\n",
       "491     12.3\n",
       "666     12.1\n",
       "400     11.1\n",
       "18      11.0\n",
       "19      11.0\n",
       "889     10.9\n",
       "442     10.6\n",
       "443     10.6\n",
       "719     10.5\n",
       "1093    10.3\n",
       "65      10.3\n",
       "1312    10.3\n",
       "1055    10.0\n",
       "891     10.0\n",
       "1311     9.6\n",
       "536      9.3\n",
       "497      9.3\n",
       "748      9.1\n",
       "1270     9.1\n",
       "Name: REB, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['REB'].sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1315, 20)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['REB'] <=13.0 ]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c93f369e88>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(df['AST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236     10.6\n",
       "1190     9.3\n",
       "121      8.7\n",
       "120      8.7\n",
       "667      8.3\n",
       "Name: AST, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AST'].sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1314, 20)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['AST'] <=10.0 ]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c93efdad08>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(df['BLK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1312    3.5\n",
       "458     3.4\n",
       "354     2.7\n",
       "318     2.6\n",
       "400     2.4\n",
       "496     2.2\n",
       "1270    2.2\n",
       "314     2.1\n",
       "274     2.1\n",
       "1163    2.1\n",
       "Name: BLK, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BLK'].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1312, 20)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['BLK'] <=3.0 ]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('TARGET_5Yrs', axis=1)\n",
    "y = df['TARGET_5Yrs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vars = df.drop('TARGET_5Yrs', axis=1)\n",
    "X_vars = sm.add_constant(X_vars)\n",
    "X_vars_train, X_vars_test, y_train, y_test = train_test_split(X_vars, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            TARGET_5Yrs   R-squared:                       0.205\n",
      "Model:                            OLS   Adj. R-squared:                  0.194\n",
      "Method:                 Least Squares   F-statistic:                     17.57\n",
      "Date:                Tue, 17 Nov 2020   Prob (F-statistic):           3.45e-52\n",
      "Time:                        01:18:30   Log-Likelihood:                -764.29\n",
      "No. Observations:                1312   AIC:                             1569.\n",
      "Df Residuals:                    1292   BIC:                             1672.\n",
      "Df Model:                          19                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.6273      0.228     -2.757      0.006      -1.074      -0.181\n",
      "GP             0.0079      0.001      8.722      0.000       0.006       0.010\n",
      "MIN           -0.0069      0.006     -1.181      0.238      -0.018       0.005\n",
      "PTS           -0.0676      0.168     -0.402      0.688      -0.398       0.262\n",
      "FGM           -0.0109      0.331     -0.033      0.974      -0.660       0.638\n",
      "FGA            0.0782      0.039      1.985      0.047       0.001       0.155\n",
      "FG%            0.0104      0.004      2.593      0.010       0.003       0.018\n",
      "3P Made        0.6749      0.243      2.780      0.006       0.199       1.151\n",
      "3PA           -0.2285      0.074     -3.095      0.002      -0.373      -0.084\n",
      "3P%            0.0007      0.001      0.666      0.506      -0.001       0.003\n",
      "FTM            0.0953      0.187      0.509      0.611      -0.272       0.462\n",
      "FTA            0.0022      0.080      0.027      0.979      -0.155       0.159\n",
      "FT%            0.0029      0.002      1.549      0.122      -0.001       0.007\n",
      "OREB           0.0904      0.244      0.370      0.711      -0.389       0.570\n",
      "DREB          -0.0644      0.243     -0.265      0.791      -0.541       0.413\n",
      "REB            0.0400      0.242      0.165      0.869      -0.435       0.515\n",
      "AST            0.0456      0.019      2.432      0.015       0.009       0.082\n",
      "STL           -0.0073      0.056     -0.130      0.896      -0.117       0.103\n",
      "BLK            0.0876      0.045      1.933      0.054      -0.001       0.176\n",
      "TOV           -0.0489      0.047     -1.033      0.302      -0.142       0.044\n",
      "==============================================================================\n",
      "Omnibus:                      414.729   Durbin-Watson:                   2.075\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               83.190\n",
      "Skew:                          -0.316   Prob(JB):                     8.62e-19\n",
      "Kurtosis:                       1.940   Cond. No.                     3.88e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.88e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "mod = sm.OLS(y, X_vars)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features we got from OLS Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | p-value |\n",
    "| --- | --- |\n",
    "| GP | 0.000 |\n",
    "| FGA | 0.047 |\n",
    "| FG% | 0.010 |\n",
    "| 3P Made | 0.006 |\n",
    "| 3PA | 0.002 |\n",
    "| AST | 0.015 |\n",
    "| BLK | (Barely qulaifies)0.054 |\n",
    "| constant | 0.006 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes - \n",
    "##### 1. R-squared close to 1 and R-squared close to Adjusted R-square indicates that the features are relevant to target.\n",
    "##### 2. Intercept only model: constant column with no other column\n",
    "##### 3. Specified model: All the features i.e., all the columns other than constant column.\n",
    "##### 4. Null-Hypothesis:(In case of F-Statistic): These 2 models are equal.\n",
    "##### 5. Alternate Hypothesis: Intercept only model is worse than specified model(our model).\n",
    "\n",
    "### F-statistic:\n",
    "##### 1. If p-value is close to 0 and f-statistic value is really large then we can reject null hypothesis.\n",
    "##### 2. In our case p-value is close to 0 and f-statistic value is large but not that large. We can reject null hypothesis i.e., the specified model(our model) fits the data better than the intercept only model(model with no columns/features except for constants). \n",
    "\n",
    "##### 3. f-statistic >1, p-value close to 0 and p- value < 0.05 indicates that the features are closely related to the target variable.\n",
    "\n",
    "### T-statistic:\n",
    "##### 1. Null-Hypothesis: the corresponding features coefficient value is going to be equal to 0.\n",
    "##### 2. Alternate-Hypothesis: the corresponding features coefficient value will not be equal to 0.\n",
    "##### 3. Here P>|t| means p-value of t-test\n",
    "##### 4. Here t means t-value\n",
    "##### 5. The higher the t-value the greater the chances that you reject the null hypothesis & you accept the alternate hypothesis.\n",
    "##### 6. If p-value is lower (i.e., p<0.05) then we reject the null hypothesis.\n",
    "##### 7. Rejecting null hypothesis means the coefficient value is non-zero.\n",
    "##### 8. Accepting null hypothesis means the coefficient value of a feature will be 0 i.e., feature will be irrelevant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.551663\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            TARGET_5Yrs   No. Observations:                 1312\n",
      "Model:                          Logit   Df Residuals:                     1292\n",
      "Method:                           MLE   Df Model:                           19\n",
      "Date:                Tue, 17 Nov 2020   Pseudo R-squ.:                  0.1708\n",
      "Time:                        01:18:30   Log-Likelihood:                -723.78\n",
      "converged:                       True   LL-Null:                       -872.92\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.526e-52\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -4.5880      1.263     -3.634      0.000      -7.063      -2.113\n",
      "GP             0.0372      0.005      7.758      0.000       0.028       0.047\n",
      "MIN           -0.0546      0.033     -1.630      0.103      -0.120       0.011\n",
      "PTS           -0.1372      0.891     -0.154      0.878      -1.883       1.609\n",
      "FGM           -0.1775      1.757     -0.101      0.920      -3.622       3.267\n",
      "FGA            0.2887      0.238      1.216      0.224      -0.177       0.754\n",
      "FG%            0.0331      0.022      1.484      0.138      -0.011       0.077\n",
      "3P Made        3.5563      1.343      2.648      0.008       0.924       6.189\n",
      "3PA           -1.2618      0.416     -3.030      0.002      -2.078      -0.446\n",
      "3P%            0.0047      0.006      0.810      0.418      -0.007       0.016\n",
      "FTM            0.6117      1.027      0.596      0.551      -1.402       2.625\n",
      "FTA           -0.1960      0.477     -0.411      0.681      -1.132       0.740\n",
      "FT%            0.0118      0.010      1.171      0.242      -0.008       0.032\n",
      "OREB           0.4330      1.290      0.336      0.737      -2.096       2.962\n",
      "DREB          -0.5590      1.286     -0.435      0.664      -3.079       1.961\n",
      "REB            0.4441      1.280      0.347      0.729      -2.064       2.952\n",
      "AST            0.3149      0.113      2.789      0.005       0.094       0.536\n",
      "STL           -0.1000      0.320     -0.313      0.754      -0.726       0.526\n",
      "BLK            0.5356      0.277      1.933      0.053      -0.008       1.079\n",
      "TOV           -0.3009      0.274     -1.099      0.272      -0.837       0.236\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "mod = sm.Logit(y, X_vars)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features we got from Logistic Regression (i.e., p < 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | p-value |\n",
    "| --- | --- |\n",
    "| GP | 0.000 |\n",
    "| 3P Made | 0.008 |\n",
    "| 3PA | 0.002 |\n",
    "| AST | 0.005 |\n",
    "| BLK | (Barely qualifies)0.053 |\n",
    "| constant | 0.000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes-\n",
    "\n",
    "#### The same rules from OLS Regression applies for Logistic Regression with a slight change where the t-value is replaced with z-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.551663\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            TARGET_5Yrs   No. Observations:                 1312\n",
      "Model:                          Logit   Df Residuals:                     1292\n",
      "Method:                           MLE   Df Model:                           19\n",
      "Date:                Tue, 17 Nov 2020   Pseudo R-squ.:                  0.1708\n",
      "Time:                        01:18:30   Log-Likelihood:                -723.78\n",
      "converged:                       True   LL-Null:                       -872.92\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.526e-52\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -4.5880      1.263     -3.634      0.000      -7.063      -2.113\n",
      "GP             0.0372      0.005      7.758      0.000       0.028       0.047\n",
      "MIN           -0.0546      0.033     -1.630      0.103      -0.120       0.011\n",
      "PTS           -0.1372      0.891     -0.154      0.878      -1.883       1.609\n",
      "FGM           -0.1775      1.757     -0.101      0.920      -3.622       3.267\n",
      "FGA            0.2887      0.238      1.216      0.224      -0.177       0.754\n",
      "FG%            0.0331      0.022      1.484      0.138      -0.011       0.077\n",
      "3P Made        3.5563      1.343      2.648      0.008       0.924       6.189\n",
      "3PA           -1.2618      0.416     -3.030      0.002      -2.078      -0.446\n",
      "3P%            0.0047      0.006      0.810      0.418      -0.007       0.016\n",
      "FTM            0.6117      1.027      0.596      0.551      -1.402       2.625\n",
      "FTA           -0.1960      0.477     -0.411      0.681      -1.132       0.740\n",
      "FT%            0.0118      0.010      1.171      0.242      -0.008       0.032\n",
      "OREB           0.4330      1.290      0.336      0.737      -2.096       2.962\n",
      "DREB          -0.5590      1.286     -0.435      0.664      -3.079       1.961\n",
      "REB            0.4441      1.280      0.347      0.729      -2.064       2.952\n",
      "AST            0.3149      0.113      2.789      0.005       0.094       0.536\n",
      "STL           -0.1000      0.320     -0.313      0.754      -0.726       0.526\n",
      "BLK            0.5356      0.277      1.933      0.053      -0.008       1.079\n",
      "TOV           -0.3009      0.274     -1.099      0.272      -0.837       0.236\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "mod = sm.Logit(y, X_vars)\n",
    "res = mod.fit(method = 'newton')\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logit Newton "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | p-value |\n",
    "| --- | --- |\n",
    "| GP | 0.000 |\n",
    "| 3P Made | 0.008 |\n",
    "| 3PA | 0.002 |\n",
    "| AST | 0.005 |\n",
    "| BLK | (Barely qualifies)0.053 |\n",
    "| constant | 0.000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods for Logistic Regression \n",
    "##### methods = ['newton'(default), bfgs, lbfgs, powell, cg, ncg, basinhopping, minimize] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.557438\n",
      "         Iterations: 35\n",
      "         Function evaluations: 40\n",
      "         Gradient evaluations: 40\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            TARGET_5Yrs   No. Observations:                 1312\n",
      "Model:                          Logit   Df Residuals:                     1292\n",
      "Method:                           MLE   Df Model:                           19\n",
      "Date:                Tue, 17 Nov 2020   Pseudo R-squ.:                  0.1622\n",
      "Time:                        01:18:30   Log-Likelihood:                -731.36\n",
      "converged:                      False   LL-Null:                       -872.92\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.691e-49\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.0070      1.242     -0.811      0.418      -3.442       1.428\n",
      "GP             0.0366      0.005      7.673      0.000       0.027       0.046\n",
      "MIN           -0.0465      0.033     -1.388      0.165      -0.112       0.019\n",
      "PTS            0.6019      0.889      0.677      0.498      -1.141       2.345\n",
      "FGM           -0.1419      1.759     -0.081      0.936      -3.589       3.305\n",
      "FGA           -0.4038      0.242     -1.667      0.095      -0.878       0.071\n",
      "FG%           -0.0304      0.023     -1.346      0.178      -0.075       0.014\n",
      "3P Made        0.6576      1.308      0.503      0.615      -1.905       3.220\n",
      "3PA           -0.3961      0.402     -0.984      0.325      -1.185       0.393\n",
      "3P%            0.0053      0.006      0.916      0.360      -0.006       0.017\n",
      "FTM            0.3654      1.029      0.355      0.723      -1.652       2.382\n",
      "FTA           -0.5827      0.484     -1.204      0.229      -1.531       0.366\n",
      "FT%           -0.0003      0.010     -0.027      0.978      -0.020       0.019\n",
      "OREB           0.7387      1.292      0.572      0.567      -1.793       3.270\n",
      "DREB          -0.4872      1.286     -0.379      0.705      -3.008       2.033\n",
      "REB            0.2939      1.281      0.230      0.818      -2.216       2.804\n",
      "AST            0.3728      0.114      3.269      0.001       0.149       0.596\n",
      "STL           -0.2391      0.322     -0.743      0.457      -0.869       0.391\n",
      "BLK            0.7280      0.287      2.537      0.011       0.166       1.290\n",
      "TOV           -0.3306      0.277     -1.192      0.233      -0.874       0.213\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mod = sm.Logit(y, X_vars)\n",
    "res = mod.fit(method = 'bfgs')\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logit Bfgs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | p-value |\n",
    "| --- | --- |\n",
    "| GP | 0.000 |\n",
    "| AST | 0.001 |\n",
    "| BLK | 0.011 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            TARGET_5Yrs   No. Observations:                 1312\n",
      "Model:                          Logit   Df Residuals:                     1292\n",
      "Method:                           MLE   Df Model:                           19\n",
      "Date:                Tue, 17 Nov 2020   Pseudo R-squ.:                  0.1323\n",
      "Time:                        01:18:30   Log-Likelihood:                -757.41\n",
      "converged:                      False   LL-Null:                       -872.92\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.119e-38\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0241      1.206     -0.020      0.984      -2.389       2.341\n",
      "GP             0.0351      0.005      7.554      0.000       0.026       0.044\n",
      "MIN           -0.0582      0.033     -1.779      0.075      -0.122       0.006\n",
      "PTS            0.1486      0.868      0.171      0.864      -1.552       1.849\n",
      "FGM            0.0536      1.711      0.031      0.975      -3.301       3.408\n",
      "FGA            0.0157      0.237      0.066      0.947      -0.448       0.480\n",
      "FG%           -0.0230      0.022     -1.044      0.296      -0.066       0.020\n",
      "3P Made       -0.0123      1.258     -0.010      0.992      -2.477       2.452\n",
      "3PA           -0.0678      0.390     -0.174      0.862      -0.832       0.696\n",
      "3P%           -0.0006      0.006     -0.115      0.909      -0.012       0.010\n",
      "FTM            0.0544      1.029      0.053      0.958      -1.962       2.071\n",
      "FTA            0.0494      0.494      0.100      0.920      -0.918       1.017\n",
      "FT%           -0.0162      0.010     -1.634      0.102      -0.036       0.003\n",
      "OREB           0.0628      1.261      0.050      0.960      -2.409       2.534\n",
      "DREB           0.0324      1.256      0.026      0.979      -2.430       2.495\n",
      "REB            0.0956      1.250      0.077      0.939      -2.355       2.546\n",
      "AST           -0.0088      0.106     -0.083      0.934      -0.216       0.199\n",
      "STL           -0.0069      0.306     -0.022      0.982      -0.607       0.594\n",
      "BLK            0.0233      0.264      0.088      0.930      -0.494       0.540\n",
      "TOV           -0.0072      0.269     -0.027      0.979      -0.534       0.519\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mod = sm.Logit(y, X_vars)\n",
    "res = mod.fit(method = 'lbfgs')\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logit Lbfgs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | p-value |\n",
    "| --- | --- |\n",
    "| GP | 0.000 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.555939\n",
      "         Iterations: 14\n",
      "         Function evaluations: 3265\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            TARGET_5Yrs   No. Observations:                 1312\n",
      "Model:                          Logit   Df Residuals:                     1292\n",
      "Method:                           MLE   Df Model:                           19\n",
      "Date:                Tue, 17 Nov 2020   Pseudo R-squ.:                  0.1644\n",
      "Time:                        01:18:31   Log-Likelihood:                -729.39\n",
      "converged:                       True   LL-Null:                       -872.92\n",
      "Covariance Type:            nonrobust   LLR p-value:                 8.946e-50\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.1934      1.235     -0.967      0.334      -3.614       1.227\n",
      "GP             0.0404      0.005      8.410      0.000       0.031       0.050\n",
      "MIN           -0.0209      0.033     -0.627      0.531      -0.086       0.044\n",
      "PTS            0.1850      0.887      0.209      0.835      -1.553       1.923\n",
      "FGM            0.1445      1.750      0.083      0.934      -3.286       3.575\n",
      "FGA           -0.1412      0.238     -0.592      0.554      -0.609       0.326\n",
      "FG%           -0.0259      0.022     -1.161      0.246      -0.070       0.018\n",
      "3P Made        2.7374      1.322      2.071      0.038       0.147       5.328\n",
      "3PA           -1.1198      0.408     -2.742      0.006      -1.920      -0.319\n",
      "3P%            0.0008      0.006      0.147      0.883      -0.010       0.012\n",
      "FTM            0.6569      1.027      0.639      0.523      -1.356       2.670\n",
      "FTA           -0.4757      0.479     -0.994      0.320      -1.414       0.463\n",
      "FT%           -0.0020      0.010     -0.195      0.845      -0.022       0.018\n",
      "OREB           0.6488      1.287      0.504      0.614      -1.874       3.171\n",
      "DREB          -0.2357      1.281     -0.184      0.854      -2.747       2.276\n",
      "REB            0.0585      1.276      0.046      0.963      -2.442       2.559\n",
      "AST            0.2279      0.112      2.044      0.041       0.009       0.446\n",
      "STL           -0.1371      0.320     -0.429      0.668      -0.764       0.489\n",
      "BLK            0.5108      0.277      1.843      0.065      -0.032       1.054\n",
      "TOV           -0.3101      0.274     -1.130      0.258      -0.848       0.228\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "mod = sm.Logit(y, X_vars)\n",
    "res = mod.fit(method = 'powell')\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logit Powell "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | p-value |\n",
    "| --- | --- |\n",
    "| GP | 0.000 |\n",
    "| 3P Made | 0.038 |\n",
    "| 3PA | 0.006 |\n",
    "| AST | 0.041 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.576157\n",
      "         Iterations: 35\n",
      "         Function evaluations: 81\n",
      "         Gradient evaluations: 81\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            TARGET_5Yrs   No. Observations:                 1312\n",
      "Model:                          Logit   Df Residuals:                     1292\n",
      "Method:                           MLE   Df Model:                           19\n",
      "Date:                Tue, 17 Nov 2020   Pseudo R-squ.:                  0.1340\n",
      "Time:                        01:18:31   Log-Likelihood:                -755.92\n",
      "converged:                      False   LL-Null:                       -872.92\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.291e-39\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0341      1.213     -0.028      0.978      -2.412       2.344\n",
      "GP             0.0369      0.005      7.884      0.000       0.028       0.046\n",
      "MIN           -0.0693      0.033     -2.105      0.035      -0.134      -0.005\n",
      "PTS            0.1715      0.870      0.197      0.844      -1.535       1.878\n",
      "FGM            0.0606      1.717      0.035      0.972      -3.305       3.427\n",
      "FGA           -0.0075      0.238     -0.032      0.975      -0.474       0.459\n",
      "FG%           -0.0300      0.022     -1.357      0.175      -0.073       0.013\n",
      "3P Made       -0.0147      1.261     -0.012      0.991      -2.487       2.457\n",
      "3PA           -0.0897      0.391     -0.229      0.819      -0.856       0.677\n",
      "3P%            0.0009      0.006      0.165      0.869      -0.010       0.012\n",
      "FTM            0.0662      1.034      0.064      0.949      -1.960       2.093\n",
      "FTA            0.0546      0.498      0.110      0.913      -0.921       1.030\n",
      "FT%           -0.0130      0.010     -1.302      0.193      -0.033       0.007\n",
      "OREB           0.0821      1.265      0.065      0.948      -2.397       2.561\n",
      "DREB           0.0374      1.261      0.030      0.976      -2.433       2.508\n",
      "REB            0.1202      1.254      0.096      0.924      -2.338       2.579\n",
      "AST            0.0006      0.106      0.006      0.995      -0.207       0.209\n",
      "STL           -0.0079      0.307     -0.026      0.979      -0.610       0.594\n",
      "BLK            0.0315      0.266      0.119      0.906      -0.490       0.553\n",
      "TOV           -0.0132      0.270     -0.049      0.961      -0.542       0.516\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mod = sm.Logit(y, X_vars)\n",
    "res = mod.fit(method = 'cg')\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logit Cg "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | p-value |\n",
    "| --- | --- |\n",
    "| GP | 0.000 |\n",
    "| MIN | 0.035 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.558943\n",
      "         Iterations: 13\n",
      "         Function evaluations: 21\n",
      "         Gradient evaluations: 33\n",
      "         Hessian evaluations: 13\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            TARGET_5Yrs   No. Observations:                 1312\n",
      "Model:                          Logit   Df Residuals:                     1292\n",
      "Method:                           MLE   Df Model:                           19\n",
      "Date:                Tue, 17 Nov 2020   Pseudo R-squ.:                  0.1599\n",
      "Time:                        01:18:31   Log-Likelihood:                -733.33\n",
      "converged:                       True   LL-Null:                       -872.92\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.642e-48\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.5710      1.240     -0.460      0.645      -3.002       1.860\n",
      "GP             0.0368      0.005      7.737      0.000       0.027       0.046\n",
      "MIN           -0.0395      0.033     -1.191      0.234      -0.105       0.026\n",
      "PTS            0.6787      0.885      0.767      0.443      -1.056       2.413\n",
      "FGM            0.1477      1.748      0.084      0.933      -3.279       3.575\n",
      "FGA           -0.5929      0.242     -2.446      0.014      -1.068      -0.118\n",
      "FG%           -0.0387      0.023     -1.715      0.086      -0.083       0.006\n",
      "3P Made        0.3026      1.301      0.233      0.816      -2.247       2.852\n",
      "3PA           -0.2592      0.399     -0.649      0.516      -1.042       0.523\n",
      "3P%            0.0024      0.006      0.424      0.672      -0.009       0.014\n",
      "FTM            0.1361      1.025      0.133      0.894      -1.874       2.146\n",
      "FTA           -0.4652      0.483     -0.964      0.335      -1.411       0.480\n",
      "FT%         7.238e-05      0.010      0.007      0.994      -0.019       0.020\n",
      "OREB           0.5848      1.285      0.455      0.649      -1.933       3.103\n",
      "DREB          -0.3694      1.278     -0.289      0.773      -2.875       2.136\n",
      "REB            0.2321      1.273      0.182      0.855      -2.263       2.727\n",
      "AST            0.3206      0.113      2.847      0.004       0.100       0.541\n",
      "STL           -0.1296      0.320     -0.405      0.686      -0.757       0.498\n",
      "BLK            0.4294      0.275      1.559      0.119      -0.110       0.969\n",
      "TOV           -0.3898      0.276     -1.414      0.157      -0.930       0.151\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "mod = sm.Logit(y, X_vars)\n",
    "res = mod.fit(method = 'ncg')\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logit Ncg "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | p-value |\n",
    "| --- | --- |\n",
    "| GP | 0.000 |\n",
    "| FGA | 0.014 |\n",
    "| AST | 0.004 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basinhopping step 0: f 0.551663\n",
      "basinhopping step 1: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "found new global minimum on step 1 with function value 0.551663\n",
      "basinhopping step 2: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 3: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "found new global minimum on step 3 with function value 0.551663\n",
      "basinhopping step 4: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 5: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 6: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 7: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 8: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 9: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 10: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 11: f 0.551665 trial_f 0.551665 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 12: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "found new global minimum on step 12 with function value 0.551663\n",
      "basinhopping step 13: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 14: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 15: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 16: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 17: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 18: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 19: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 20: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 21: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 22: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 23: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 24: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 25: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 26: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 27: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 28: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 29: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 30: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 31: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 32: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 33: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 34: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 35: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 36: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 37: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 38: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 39: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 40: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 41: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 42: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 43: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 44: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 45: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 46: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 47: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 48: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 49: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "adaptive stepsize: acceptance rate 0.980000 target 0.500000 new stepsize 0.555556 old stepsize 0.5\n",
      "basinhopping step 50: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 51: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 52: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 53: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 54: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 55: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 56: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 57: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "found new global minimum on step 57 with function value 0.551663\n",
      "basinhopping step 58: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 59: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 60: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 61: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 62: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 63: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 64: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 65: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 66: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 67: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 68: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 69: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 70: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 71: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 72: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 73: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 74: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 75: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 76: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 77: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 78: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 79: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 80: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 81: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 82: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 83: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 84: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 85: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 86: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 87: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 88: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 89: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 90: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 91: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 92: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 93: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 94: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 95: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 96: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 97: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 98: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n",
      "basinhopping step 99: f 0.551663 trial_f 0.551663 accepted 1  lowest_f 0.551663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adaptive stepsize: acceptance rate 0.990000 target 0.500000 new stepsize 0.617284 old stepsize 0.555556\n",
      "basinhopping step 100: f 0.551664 trial_f 0.551664 accepted 1  lowest_f 0.551663\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            TARGET_5Yrs   No. Observations:                 1312\n",
      "Model:                          Logit   Df Residuals:                     1292\n",
      "Method:                           MLE   Df Model:                           19\n",
      "Date:                Tue, 17 Nov 2020   Pseudo R-squ.:                  0.1708\n",
      "Time:                        01:18:34   Log-Likelihood:                -723.78\n",
      "converged:                       True   LL-Null:                       -872.92\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.526e-52\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -4.5897      1.263     -3.635      0.000      -7.064      -2.115\n",
      "GP             0.0372      0.005      7.758      0.000       0.028       0.047\n",
      "MIN           -0.0546      0.033     -1.630      0.103      -0.120       0.011\n",
      "PTS           -0.1369      0.891     -0.154      0.878      -1.883       1.609\n",
      "FGM           -0.1785      1.757     -0.102      0.919      -3.623       3.266\n",
      "FGA            0.2888      0.238      1.216      0.224      -0.177       0.754\n",
      "FG%            0.0331      0.022      1.485      0.137      -0.011       0.077\n",
      "3P Made        3.5544      1.343      2.646      0.008       0.922       6.187\n",
      "3PA           -1.2612      0.416     -3.029      0.002      -2.077      -0.445\n",
      "3P%            0.0047      0.006      0.811      0.418      -0.007       0.016\n",
      "FTM            0.6110      1.027      0.595      0.552      -1.402       2.624\n",
      "FTA           -0.1958      0.477     -0.410      0.682      -1.132       0.740\n",
      "FT%            0.0119      0.010      1.172      0.241      -0.008       0.032\n",
      "OREB           0.4322      1.290      0.335      0.738      -2.097       2.961\n",
      "DREB          -0.5598      1.286     -0.435      0.663      -3.080       1.960\n",
      "REB            0.4449      1.280      0.348      0.728      -2.063       2.953\n",
      "AST            0.3149      0.113      2.789      0.005       0.094       0.536\n",
      "STL           -0.1000      0.320     -0.313      0.754      -0.726       0.526\n",
      "BLK            0.5358      0.277      1.933      0.053      -0.007       1.079\n",
      "TOV           -0.3008      0.274     -1.099      0.272      -0.837       0.236\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "mod = sm.Logit(y, X_vars)\n",
    "res = mod.fit(method = 'basinhopping')\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logit Basinhopping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | p-value |\n",
    "| --- | --- |\n",
    "| GP | 0.000 |\n",
    "| 3P Made | 0.008 |\n",
    "| 3PA | 0.002 |\n",
    "| AST | 0.005|\n",
    "| BLK | (Barely qualifies)0.053 |\n",
    "| constant | 0.000 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.557438\n",
      "         Iterations: 35\n",
      "         Function evaluations: 40\n",
      "         Gradient evaluations: 40\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            TARGET_5Yrs   No. Observations:                 1312\n",
      "Model:                          Logit   Df Residuals:                     1292\n",
      "Method:                           MLE   Df Model:                           19\n",
      "Date:                Tue, 17 Nov 2020   Pseudo R-squ.:                  0.1622\n",
      "Time:                        01:18:34   Log-Likelihood:                -731.36\n",
      "converged:                      False   LL-Null:                       -872.92\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.691e-49\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.0070      1.242     -0.811      0.418      -3.442       1.428\n",
      "GP             0.0366      0.005      7.673      0.000       0.027       0.046\n",
      "MIN           -0.0465      0.033     -1.388      0.165      -0.112       0.019\n",
      "PTS            0.6019      0.889      0.677      0.498      -1.141       2.345\n",
      "FGM           -0.1419      1.759     -0.081      0.936      -3.589       3.305\n",
      "FGA           -0.4038      0.242     -1.667      0.095      -0.878       0.071\n",
      "FG%           -0.0304      0.023     -1.346      0.178      -0.075       0.014\n",
      "3P Made        0.6576      1.308      0.503      0.615      -1.905       3.220\n",
      "3PA           -0.3961      0.402     -0.984      0.325      -1.185       0.393\n",
      "3P%            0.0053      0.006      0.916      0.360      -0.006       0.017\n",
      "FTM            0.3654      1.029      0.355      0.723      -1.652       2.382\n",
      "FTA           -0.5827      0.484     -1.204      0.229      -1.531       0.366\n",
      "FT%           -0.0003      0.010     -0.027      0.978      -0.020       0.019\n",
      "OREB           0.7387      1.292      0.572      0.567      -1.793       3.270\n",
      "DREB          -0.4872      1.286     -0.379      0.705      -3.008       2.033\n",
      "REB            0.2939      1.281      0.230      0.818      -2.216       2.804\n",
      "AST            0.3728      0.114      3.269      0.001       0.149       0.596\n",
      "STL           -0.2391      0.322     -0.743      0.457      -0.869       0.391\n",
      "BLK            0.7280      0.287      2.537      0.011       0.166       1.290\n",
      "TOV           -0.3306      0.277     -1.192      0.233      -0.874       0.213\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mod = sm.Logit(y, X_vars)\n",
    "res = mod.fit(method = 'minimize')\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logit Minimize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | p-value |\n",
    "| --- | --- |\n",
    "| GP | 0.000 |\n",
    "| AST | 0.001|\n",
    "| BLK | 0.011 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can see that newton and basinhopping have same features and p-values. So we are gonna select these features for modeling from Logistic Regression. They are: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | p-value |\n",
    "| --- | --- |\n",
    "| GP | 0.000 |\n",
    "| 3P Made | 0.008 |\n",
    "| 3PA | 0.002 |\n",
    "| AST | 0.005|\n",
    "| BLK | (Barely qualifies)0.053 |\n",
    "| constant | 0.000 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import VarianceThreshold, RFE, SelectFromModel, SelectKBest, f_classif, chi2, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(984, 19)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing features with low variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(984, 19)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_variance_threshold = VarianceThreshold() \n",
    "X_train_remove_variance = sel_variance_threshold.fit_transform(X_train)\n",
    "X_train_remove_variance.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data still has 19 features, so no feature is removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection using SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "From 'chi2' score-function\n",
      "\n",
      "    Features       Score\n",
      "0        GP  730.428324\n",
      "1       MIN  315.469383\n",
      "2       PTS  223.987686\n",
      "4       FGA  147.463620\n",
      "14      REB  105.073961\n",
      "3       FGM   87.975609\n",
      "10      FTA   72.112447\n",
      "13     DREB   60.915314\n",
      "9       FTM   54.639543\n",
      "5       FG%   47.700707\n"
     ]
    }
   ],
   "source": [
    "bestfeatures1 = SelectKBest(score_func = chi2, k = 10)\n",
    "fit1 = bestfeatures1.fit(X_train,y_train)\n",
    "dfscores1 = pd.DataFrame(fit1.scores_)\n",
    "dfcolumns1 = pd.DataFrame(X_train.columns)\n",
    "\n",
    "featureScores1 = pd.concat([dfcolumns1,dfscores1],axis=1)\n",
    "featureScores1.columns = ['Features','Score']  \n",
    "print(\"\\nFrom 'chi2' score-function\\n\\n\", featureScores1.nlargest(10,'Score')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "From 'f_classif' score-function\n",
      "\n",
      "    Features       Score\n",
      "0        GP  172.494989\n",
      "3       FGM   92.504370\n",
      "2       PTS   91.382153\n",
      "1       MIN   88.691227\n",
      "10      FTA   87.183422\n",
      "14      REB   84.673581\n",
      "9       FTM   84.388287\n",
      "12     OREB   84.230517\n",
      "4       FGA   73.845814\n",
      "13     DREB   73.761657\n"
     ]
    }
   ],
   "source": [
    "bestfeatures2 = SelectKBest(score_func = f_classif, k=10)\n",
    "fit2 = bestfeatures2.fit(X_train,y_train)\n",
    "dfscores2 = pd.DataFrame(fit2.scores_)\n",
    "dfcolumns2 = pd.DataFrame(X_train.columns)\n",
    "\n",
    "featureScores2 = pd.concat([dfcolumns2,dfscores2],axis = 1)\n",
    "featureScores2.columns = ['Features','Score']  \n",
    "print(\"\\nFrom 'f_classif' score-function\\n\\n\", featureScores2.nlargest(10,'Score')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "From 'mutual_info_classif' score-function\n",
      "\n",
      "    Features     Score\n",
      "3       FGM  0.075798\n",
      "0        GP  0.063791\n",
      "9       FTM  0.059927\n",
      "2       PTS  0.055446\n",
      "14      REB  0.048987\n",
      "12     OREB  0.041619\n",
      "10      FTA  0.041378\n",
      "1       MIN  0.040952\n",
      "18      TOV  0.033067\n",
      "13     DREB  0.032396\n"
     ]
    }
   ],
   "source": [
    "bestfeatures3 = SelectKBest(score_func = mutual_info_classif, k=10)\n",
    "fit3 = bestfeatures3.fit(X_train,y_train)\n",
    "dfscores3 = pd.DataFrame(fit3.scores_)\n",
    "dfcolumns3 = pd.DataFrame(X_train.columns)\n",
    "\n",
    "featureScores3 = pd.concat([dfcolumns3,dfscores3],axis = 1)\n",
    "featureScores3.columns = ['Features','Score']  \n",
    "print(\"\\nFrom 'mutual_info_classif' score-function\\n\\n\", featureScores3.nlargest(10,'Score')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### score_func = ['f_classif', 'mutual_info_classif', 'chi2', 'f_regression', 'mutual_info_regression', 'SelectPercentile', 'SelectFpr', 'SelectFdr', 'SelectFwe', 'GenericUnivariateSelect'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model_logistic = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000)\n",
    "sel_rfe_logistic = RFE(estimator=model_logistic, n_features_to_select=10, step=1)\n",
    "X_train_rfe_logistic = sel_rfe_logistic.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True  True False  True  True False  True  True False\n",
      "  True False False  True  True  True False]\n",
      "{'estimator__C': 1.0, 'estimator__class_weight': None, 'estimator__dual': False, 'estimator__fit_intercept': True, 'estimator__intercept_scaling': 1, 'estimator__l1_ratio': None, 'estimator__max_iter': 1000, 'estimator__multi_class': 'multinomial', 'estimator__n_jobs': None, 'estimator__penalty': 'l2', 'estimator__random_state': None, 'estimator__solver': 'lbfgs', 'estimator__tol': 0.0001, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False), 'n_features_to_select': 10, 'step': 1, 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "print(sel_rfe_logistic.get_support())\n",
    "print(sel_rfe_logistic.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  6,  8,  1,  1,  5,  1,  1, 10,  1,  1,  9,  1,  2,  3,  1,  1,\n",
       "        1,  4])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_rfe_logistic.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features with only rank 1 are selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected are: \n",
      "Column: FGM\n",
      "Column: FGA\n",
      "Column: 3P Made\n",
      "Column: 3PA\n",
      "Column: FTM\n",
      "Column: FTA\n",
      "Column: OREB\n",
      "Column: AST\n",
      "Column: STL\n",
      "Column: BLK\n"
     ]
    }
   ],
   "source": [
    "print(\"Features Selected are: \")\n",
    "for i in range(X_train.shape[1]):\n",
    "    if sel_rfe_logistic.support_[i] == True:\n",
    "        print('Column: %s' % (X_train.columns[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree = RandomForestClassifier(random_state=100, n_estimators=50)\n",
    "sel_rfe_tree = RFE(estimator=model_tree, n_features_to_select=10, step=1)\n",
    "X_train_rfe_tree = sel_rfe_tree.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True False  True  True False False False  True  True  True\n",
      " False False  True  True False False False]\n",
      "{'estimator__bootstrap': True, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__max_leaf_nodes': None, 'estimator__max_samples': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_impurity_split': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 50, 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': 100, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
      "                       n_jobs=None, oob_score=False, random_state=100,\n",
      "                       verbose=0, warm_start=False), 'n_features_to_select': 10, 'step': 1, 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "print(sel_rfe_tree.get_support())\n",
    "print(sel_rfe_tree.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1,  3,  1,  1, 10,  6,  5,  1,  1,  1,  2,  4,  1,  1,  9,\n",
       "        8,  7])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_rfe_tree.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selected are: \n",
      "Column: GP\n",
      "Column: MIN\n",
      "Column: PTS\n",
      "Column: FGA\n",
      "Column: FG%\n",
      "Column: FTM\n",
      "Column: FTA\n",
      "Column: FT%\n",
      "Column: REB\n",
      "Column: AST\n"
     ]
    }
   ],
   "source": [
    "print(\"Features Selected are: \")\n",
    "for i in range(X_train.shape[1]):\n",
    "    if sel_rfe_tree.support_[i] == True:\n",
    "        print('Column: %s' % (X_train.columns[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection using SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) L1-based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logistic = LogisticRegression(solver='saga', multi_class='multinomial', max_iter=10000, penalty='l1')\n",
    "sel_model_logistic = SelectFromModel(estimator=model_logistic)\n",
    "X_train_sfm_l1 = sel_model_logistic.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True False  True  True  True  True  True  True  True  True\n",
      "  True  True False  True  True  True  True]\n",
      "{'estimator__C': 1.0, 'estimator__class_weight': None, 'estimator__dual': False, 'estimator__fit_intercept': True, 'estimator__intercept_scaling': 1, 'estimator__l1_ratio': None, 'estimator__max_iter': 10000, 'estimator__multi_class': 'multinomial', 'estimator__n_jobs': None, 'estimator__penalty': 'l1', 'estimator__random_state': None, 'estimator__solver': 'saga', 'estimator__tol': 0.0001, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
      "                   multi_class='multinomial', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
      "                   warm_start=False), 'max_features': None, 'norm_order': 1, 'prefit': False, 'threshold': None}\n"
     ]
    }
   ],
   "source": [
    "print(sel_model_logistic.get_support())\n",
    "print(sel_model_logistic.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected by SelectFromModel: Index(['GP', 'MIN', 'PTS', 'FGA', 'FG%', '3P Made', '3PA', '3P%', 'FTM', 'FTA',\n",
      "       'FT%', 'OREB', 'DREB', 'AST', 'STL', 'BLK', 'TOV'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "feature_names = X_train.columns\n",
    "print(\"Features selected by SelectFromModel: \"\n",
    "      f\"{feature_names[sel_model_logistic.get_support()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Tree-based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09583504 0.05336147 0.05921336 0.05435793 0.04830798 0.06062864\n",
      " 0.03063386 0.04315281 0.04378697 0.05529345 0.05039769 0.04992243\n",
      " 0.05490673 0.05167443 0.05884954 0.04842301 0.04497474 0.04562186\n",
      " 0.05065805]\n"
     ]
    }
   ],
   "source": [
    "model_tree = ExtraTreesClassifier(random_state=100, n_estimators=50)\n",
    "model_tree.fit(X_train, y_train)\n",
    "print(model_tree.feature_importances_)\n",
    "\n",
    "sel_model_tree = SelectFromModel(estimator=model_tree, prefit=True, threshold='mean')\n",
    "X_train_sfm_tree = sel_model_tree.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True False  True False False False  True False False\n",
      "  True False  True False False False False]\n",
      "{'estimator__bootstrap': False, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__max_leaf_nodes': None, 'estimator__max_samples': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_impurity_split': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 50, 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': 100, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
      "                     oob_score=False, random_state=100, verbose=0,\n",
      "                     warm_start=False), 'max_features': None, 'norm_order': 1, 'prefit': True, 'threshold': 'mean'}\n"
     ]
    }
   ],
   "source": [
    "print(sel_model_tree.get_support())\n",
    "print(sel_model_tree.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected by SelectFromModel: Index(['GP', 'MIN', 'PTS', 'FGM', 'FG%', 'FTM', 'OREB', 'REB'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "feature_names = X_train.columns\n",
    "print(\"Features selected by SelectFromModel: \"\n",
    "      f\"{feature_names[sel_model_tree.get_support()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimiztion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing with models that got highest accuracy from each area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 68  61]\n",
      " [ 36 163]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.53      0.58       129\n",
      "         1.0       0.73      0.82      0.77       199\n",
      "\n",
      "    accuracy                           0.70       328\n",
      "   macro avg       0.69      0.67      0.68       328\n",
      "weighted avg       0.70      0.70      0.70       328\n",
      "\n",
      "Score: \n",
      " 70.73\n",
      "Test Score: \n",
      " 70.43\n",
      "Accuracy: \n",
      " 0.7042682926829268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_bs_af =  LogisticRegression(random_state = 11)\n",
    "lr_bs_af.fit(X_train, y_train)\n",
    "y_pred = lr_bs_af.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "lr_bs_af_score = round(lr_bs_af.score(X_train, y_train) * 100, 2)\n",
    "lr_bs_af_score_test = round(lr_bs_af.score(X_test, y_test) * 100, 2)\n",
    "print('Score: \\n', lr_bs_af_score)\n",
    "print('Test Score: \\n', lr_bs_af_score_test)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 800 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 811 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1591 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2384 tasks      | elapsed:   59.2s\n",
      "[Parallel(n_jobs=-1)]: Done 3098 tasks      | elapsed:  1.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 4.281332398719396, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 11, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} \n",
      "\n",
      "Model accuracy is 0.7195121951219512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed:  2.5min finished\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "param_grid = [\n",
    "    {'penalty' : ['l1', 'l2'],\n",
    "    'C': np.logspace(-4, 4, 20),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000,2500, 5000]}\n",
    "]\n",
    "\n",
    "lr_bs_af_gscv = GridSearchCV(lr_bs_af, param_grid = param_grid, cv = kfold, verbose=True, n_jobs=-1)\n",
    "best_lr_bs_af_gscv = lr_bs_af_gscv.fit(X_train, y_train)\n",
    "\n",
    "print(best_lr_bs_af_gscv.best_estimator_.get_params(), '\\n')\n",
    "print('Model accuracy is',best_lr_bs_af_gscv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy          :  0.7195121951219512 \n",
      " Balanced Accuracy :  0.7121752880054213 \n",
      " Precision         :  0.8542713567839196 \n",
      " Average Precision :  0.8153612851234082 \n",
      " F1-Score          :  0.787037037037037 \n",
      " Recall            :  0.7296137339055794 \n",
      " ROC-AUC           :  0.7886720423824548 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.69      0.59        95\n",
      "         1.0       0.85      0.73      0.79       233\n",
      "\n",
      "    accuracy                           0.72       328\n",
      "   macro avg       0.68      0.71      0.69       328\n",
      "weighted avg       0.76      0.72      0.73       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "probs = best_lr_bs_af_gscv.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "classes = best_lr_bs_af_gscv.predict(X_test)\n",
    "    \n",
    "accuracy = metrics.accuracy_score(classes, y_test)\n",
    "    \n",
    "balanced_accuracy = metrics.balanced_accuracy_score(classes, y_test)\n",
    "\n",
    "precision = metrics.precision_score(classes, y_test)\n",
    "    \n",
    "average_precision = metrics.average_precision_score(classes, y_test)\n",
    "    \n",
    "f1_score = metrics.f1_score(classes, y_test)\n",
    "    \n",
    "recall = metrics.recall_score(classes, y_test)\n",
    "\n",
    "print (\"\\n Accuracy          : \", accuracy, \"\\n Balanced Accuracy : \", balanced_accuracy, \"\\n Precision         : \", precision, \"\\n Average Precision : \", average_precision, \"\\n F1-Score          : \", f1_score, \"\\n Recall            : \", recall, \"\\n ROC-AUC           : \", roc_auc, \"\\n\")\n",
    "\n",
    "print(metrics.classification_report(classes, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.615848211066026, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 11, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} \n",
      "\n",
      "Model accuracy is 0.725609756097561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    4.6s finished\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "param_grid = [\n",
    "    {'penalty' : ['l1', 'l2'],\n",
    "    'C': np.logspace(-4, 4, 20),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000,2500, 5000]}\n",
    "]\n",
    "\n",
    "lr_bs_af_rscv = RandomizedSearchCV(lr_bs_af, param_distributions = param_grid, cv = kfold, verbose=True, n_jobs=-1, random_state = 11)\n",
    "best_lr_bs_af_rscv = lr_bs_af_rscv.fit(X_train, y_train)\n",
    "\n",
    "print(best_lr_bs_af_rscv.best_estimator_.get_params(), '\\n')\n",
    "print('Model accuracy is',best_lr_bs_af_rscv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy          :  0.725609756097561 \n",
      " Balanced Accuracy :  0.7184808318828937 \n",
      " Precision         :  0.8542713567839196 \n",
      " Average Precision :  0.8146601580386358 \n",
      " F1-Score          :  0.7906976744186045 \n",
      " Recall            :  0.7359307359307359 \n",
      " ROC-AUC           :  0.7848155506213237 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.70      0.60        97\n",
      "         1.0       0.85      0.74      0.79       231\n",
      "\n",
      "    accuracy                           0.73       328\n",
      "   macro avg       0.69      0.72      0.70       328\n",
      "weighted avg       0.76      0.73      0.73       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "probs = best_lr_bs_af_rscv.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "classes = best_lr_bs_af_rscv.predict(X_test)\n",
    "    \n",
    "accuracy = metrics.accuracy_score(classes, y_test)\n",
    "    \n",
    "balanced_accuracy = metrics.balanced_accuracy_score(classes, y_test)\n",
    "\n",
    "precision = metrics.precision_score(classes, y_test)\n",
    "    \n",
    "average_precision = metrics.average_precision_score(classes, y_test)\n",
    "    \n",
    "f1_score = metrics.f1_score(classes, y_test)\n",
    "    \n",
    "recall = metrics.recall_score(classes, y_test)\n",
    "\n",
    "print (\"\\n Accuracy          : \", accuracy, \"\\n Balanced Accuracy : \", balanced_accuracy, \"\\n Precision         : \", precision, \"\\n Average Precision : \", average_precision, \"\\n F1-Score          : \", f1_score, \"\\n Recall            : \", recall, \"\\n ROC-AUC           : \", roc_auc, \"\\n\")\n",
    "\n",
    "print(metrics.classification_report(classes, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:17<00:00,  5.82trial/s, best loss: -0.7033046721226561]\n",
      "best:\n",
      "{'C': 9.256221100460834, 'max_iter': 2, 'penalty': 1, 'solver': 0}\n",
      "Accuracy :  70.33046721226562\n"
     ]
    }
   ],
   "source": [
    "def f(params):\n",
    "    acc = hyperopt_train_test(params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "def hyperopt_train_test(params):\n",
    "    lr_bs_af_bo = LogisticRegression(**params, random_state = 11)\n",
    "    return sklearn.model_selection.cross_val_score(lr_bs_af_bo, X_train, y_train).mean()\n",
    "\n",
    "param_grid = {\n",
    "    'C': hp.uniform('C', 0, 20),\n",
    "    'penalty': hp.choice('penalty', ['l1', 'l2']),\n",
    "    'solver': hp.choice('solver', ['lbfgs','newton-cg','liblinear','sag','saga']),\n",
    "    'max_iter' : hp.choice('max_iter', [100, 1000,2500, 5000])\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(f, param_grid, algo=tpe.suggest, max_evals=100, trials=trials)\n",
    "print('best:')\n",
    "print(best)\n",
    "print(\"Accuracy : \", -trials.best_trial['result']['loss']*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = X_train.mean()\n",
    "train_std = X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.384826e-17</td>\n",
       "      <td>1.358218e-15</td>\n",
       "      <td>-1.343212e-15</td>\n",
       "      <td>5.451827e-16</td>\n",
       "      <td>-1.886928e-15</td>\n",
       "      <td>-1.311665e-14</td>\n",
       "      <td>1.186043e-15</td>\n",
       "      <td>-1.324370e-15</td>\n",
       "      <td>5.325460e-17</td>\n",
       "      <td>-1.836550e-15</td>\n",
       "      <td>1.356695e-15</td>\n",
       "      <td>6.320035e-15</td>\n",
       "      <td>3.456754e-16</td>\n",
       "      <td>1.510535e-15</td>\n",
       "      <td>-1.996314e-15</td>\n",
       "      <td>6.514662e-16</td>\n",
       "      <td>-5.424748e-16</td>\n",
       "      <td>-2.123866e-15</td>\n",
       "      <td>-7.536880e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.845202e+00</td>\n",
       "      <td>-1.629782e+00</td>\n",
       "      <td>-1.420027e+00</td>\n",
       "      <td>-1.399677e+00</td>\n",
       "      <td>-1.424223e+00</td>\n",
       "      <td>-2.812406e+00</td>\n",
       "      <td>-6.520126e-01</td>\n",
       "      <td>-7.413625e-01</td>\n",
       "      <td>-1.228266e+00</td>\n",
       "      <td>-1.239768e+00</td>\n",
       "      <td>-1.328974e+00</td>\n",
       "      <td>-4.085970e+00</td>\n",
       "      <td>-1.308417e+00</td>\n",
       "      <td>-1.353180e+00</td>\n",
       "      <td>-1.342269e+00</td>\n",
       "      <td>-1.053552e+00</td>\n",
       "      <td>-1.523710e+00</td>\n",
       "      <td>-9.190461e-01</td>\n",
       "      <td>-1.506809e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.655035e-01</td>\n",
       "      <td>-8.168270e-01</td>\n",
       "      <td>-7.364365e-01</td>\n",
       "      <td>-7.308572e-01</td>\n",
       "      <td>-7.461772e-01</td>\n",
       "      <td>-6.568735e-01</td>\n",
       "      <td>-6.520126e-01</td>\n",
       "      <td>-7.413625e-01</td>\n",
       "      <td>-1.228266e+00</td>\n",
       "      <td>-7.107428e-01</td>\n",
       "      <td>-6.973822e-01</td>\n",
       "      <td>-5.492547e-01</td>\n",
       "      <td>-7.801651e-01</td>\n",
       "      <td>-7.531557e-01</td>\n",
       "      <td>-7.448281e-01</td>\n",
       "      <td>-6.398944e-01</td>\n",
       "      <td>-7.777742e-01</td>\n",
       "      <td>-6.653027e-01</td>\n",
       "      <td>-6.663555e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.010378e-01</td>\n",
       "      <td>-1.737431e-01</td>\n",
       "      <td>-2.885666e-01</td>\n",
       "      <td>-3.052447e-01</td>\n",
       "      <td>-2.941470e-01</td>\n",
       "      <td>1.304316e-03</td>\n",
       "      <td>-3.920530e-01</td>\n",
       "      <td>-4.586103e-01</td>\n",
       "      <td>2.082489e-01</td>\n",
       "      <td>-2.875229e-01</td>\n",
       "      <td>-2.236886e-01</td>\n",
       "      <td>8.691529e-02</td>\n",
       "      <td>-2.519129e-01</td>\n",
       "      <td>-2.281343e-01</td>\n",
       "      <td>-2.469605e-01</td>\n",
       "      <td>-2.951796e-01</td>\n",
       "      <td>-2.804839e-01</td>\n",
       "      <td>-4.115594e-01</td>\n",
       "      <td>-2.461287e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.675790e-01</td>\n",
       "      <td>6.392119e-01</td>\n",
       "      <td>4.657407e-01</td>\n",
       "      <td>4.851784e-01</td>\n",
       "      <td>4.686541e-01</td>\n",
       "      <td>6.101188e-01</td>\n",
       "      <td>3.878260e-01</td>\n",
       "      <td>3.896464e-01</td>\n",
       "      <td>8.828287e-01</td>\n",
       "      <td>3.473070e-01</td>\n",
       "      <td>4.079028e-01</td>\n",
       "      <td>6.743366e-01</td>\n",
       "      <td>5.404653e-01</td>\n",
       "      <td>4.468932e-01</td>\n",
       "      <td>4.500541e-01</td>\n",
       "      <td>2.563641e-01</td>\n",
       "      <td>4.654516e-01</td>\n",
       "      <td>3.496707e-01</td>\n",
       "      <td>4.542492e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.256426e+00</td>\n",
       "      <td>2.835404e+00</td>\n",
       "      <td>3.812979e+00</td>\n",
       "      <td>3.890078e+00</td>\n",
       "      <td>3.915385e+00</td>\n",
       "      <td>3.637737e+00</td>\n",
       "      <td>4.807140e+00</td>\n",
       "      <td>4.065425e+00</td>\n",
       "      <td>2.078307e+00</td>\n",
       "      <td>5.002726e+00</td>\n",
       "      <td>5.302736e+00</td>\n",
       "      <td>2.875339e+00</td>\n",
       "      <td>4.370294e+00</td>\n",
       "      <td>5.097083e+00</td>\n",
       "      <td>4.632142e+00</td>\n",
       "      <td>5.358143e+00</td>\n",
       "      <td>4.692420e+00</td>\n",
       "      <td>5.932025e+00</td>\n",
       "      <td>4.236290e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 GP           MIN           PTS           FGM           FGA  \\\n",
       "count  9.840000e+02  9.840000e+02  9.840000e+02  9.840000e+02  9.840000e+02   \n",
       "mean   3.384826e-17  1.358218e-15 -1.343212e-15  5.451827e-16 -1.886928e-15   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.845202e+00 -1.629782e+00 -1.420027e+00 -1.399677e+00 -1.424223e+00   \n",
       "25%   -7.655035e-01 -8.168270e-01 -7.364365e-01 -7.308572e-01 -7.461772e-01   \n",
       "50%    1.010378e-01 -1.737431e-01 -2.885666e-01 -3.052447e-01 -2.941470e-01   \n",
       "75%    9.675790e-01  6.392119e-01  4.657407e-01  4.851784e-01  4.686541e-01   \n",
       "max    1.256426e+00  2.835404e+00  3.812979e+00  3.890078e+00  3.915385e+00   \n",
       "\n",
       "                FG%       3P Made           3PA           3P%           FTM  \\\n",
       "count  9.840000e+02  9.840000e+02  9.840000e+02  9.840000e+02  9.840000e+02   \n",
       "mean  -1.311665e-14  1.186043e-15 -1.324370e-15  5.325460e-17 -1.836550e-15   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.812406e+00 -6.520126e-01 -7.413625e-01 -1.228266e+00 -1.239768e+00   \n",
       "25%   -6.568735e-01 -6.520126e-01 -7.413625e-01 -1.228266e+00 -7.107428e-01   \n",
       "50%    1.304316e-03 -3.920530e-01 -4.586103e-01  2.082489e-01 -2.875229e-01   \n",
       "75%    6.101188e-01  3.878260e-01  3.896464e-01  8.828287e-01  3.473070e-01   \n",
       "max    3.637737e+00  4.807140e+00  4.065425e+00  2.078307e+00  5.002726e+00   \n",
       "\n",
       "                FTA           FT%          OREB          DREB           REB  \\\n",
       "count  9.840000e+02  9.840000e+02  9.840000e+02  9.840000e+02  9.840000e+02   \n",
       "mean   1.356695e-15  6.320035e-15  3.456754e-16  1.510535e-15 -1.996314e-15   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.328974e+00 -4.085970e+00 -1.308417e+00 -1.353180e+00 -1.342269e+00   \n",
       "25%   -6.973822e-01 -5.492547e-01 -7.801651e-01 -7.531557e-01 -7.448281e-01   \n",
       "50%   -2.236886e-01  8.691529e-02 -2.519129e-01 -2.281343e-01 -2.469605e-01   \n",
       "75%    4.079028e-01  6.743366e-01  5.404653e-01  4.468932e-01  4.500541e-01   \n",
       "max    5.302736e+00  2.875339e+00  4.370294e+00  5.097083e+00  4.632142e+00   \n",
       "\n",
       "                AST           STL           BLK           TOV  \n",
       "count  9.840000e+02  9.840000e+02  9.840000e+02  9.840000e+02  \n",
       "mean   6.514662e-16 -5.424748e-16 -2.123866e-15 -7.536880e-17  \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "min   -1.053552e+00 -1.523710e+00 -9.190461e-01 -1.506809e+00  \n",
       "25%   -6.398944e-01 -7.777742e-01 -6.653027e-01 -6.663555e-01  \n",
       "50%   -2.951796e-01 -2.804839e-01 -4.115594e-01 -2.461287e-01  \n",
       "75%    2.563641e-01  4.654516e-01  3.496707e-01  4.542492e-01  \n",
       "max    5.358143e+00  4.692420e+00  5.932025e+00  4.236290e+00  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = (X_test - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.018258</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.009606</td>\n",
       "      <td>0.010072</td>\n",
       "      <td>-0.002412</td>\n",
       "      <td>0.033611</td>\n",
       "      <td>-0.056008</td>\n",
       "      <td>-0.056033</td>\n",
       "      <td>-0.000789</td>\n",
       "      <td>0.031505</td>\n",
       "      <td>0.040357</td>\n",
       "      <td>-0.046638</td>\n",
       "      <td>0.047645</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>0.015634</td>\n",
       "      <td>0.018637</td>\n",
       "      <td>0.022742</td>\n",
       "      <td>-0.039454</td>\n",
       "      <td>0.037866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.011584</td>\n",
       "      <td>0.980169</td>\n",
       "      <td>0.984359</td>\n",
       "      <td>0.999085</td>\n",
       "      <td>0.979138</td>\n",
       "      <td>0.983559</td>\n",
       "      <td>0.905094</td>\n",
       "      <td>0.900421</td>\n",
       "      <td>1.005049</td>\n",
       "      <td>0.960512</td>\n",
       "      <td>0.959364</td>\n",
       "      <td>1.047490</td>\n",
       "      <td>1.015325</td>\n",
       "      <td>0.973646</td>\n",
       "      <td>0.992538</td>\n",
       "      <td>0.958121</td>\n",
       "      <td>0.992125</td>\n",
       "      <td>0.987205</td>\n",
       "      <td>0.953656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.614125</td>\n",
       "      <td>-1.605515</td>\n",
       "      <td>-1.325739</td>\n",
       "      <td>-1.338875</td>\n",
       "      <td>-1.311215</td>\n",
       "      <td>-3.338948</td>\n",
       "      <td>-0.652013</td>\n",
       "      <td>-0.741363</td>\n",
       "      <td>-1.228266</td>\n",
       "      <td>-1.239768</td>\n",
       "      <td>-1.328974</td>\n",
       "      <td>-3.822727</td>\n",
       "      <td>-1.176354</td>\n",
       "      <td>-1.278177</td>\n",
       "      <td>-1.292482</td>\n",
       "      <td>-1.053552</td>\n",
       "      <td>-1.523710</td>\n",
       "      <td>-0.919046</td>\n",
       "      <td>-1.506809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.722176</td>\n",
       "      <td>-0.819860</td>\n",
       "      <td>-0.689292</td>\n",
       "      <td>-0.730857</td>\n",
       "      <td>-0.696736</td>\n",
       "      <td>-0.595169</td>\n",
       "      <td>-0.652013</td>\n",
       "      <td>-0.741363</td>\n",
       "      <td>-1.228266</td>\n",
       "      <td>-0.604938</td>\n",
       "      <td>-0.618433</td>\n",
       "      <td>-0.615065</td>\n",
       "      <td>-0.681118</td>\n",
       "      <td>-0.753156</td>\n",
       "      <td>-0.744828</td>\n",
       "      <td>-0.639894</td>\n",
       "      <td>-0.777774</td>\n",
       "      <td>-0.665303</td>\n",
       "      <td>-0.666356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.216577</td>\n",
       "      <td>-0.191944</td>\n",
       "      <td>-0.264995</td>\n",
       "      <td>-0.305245</td>\n",
       "      <td>-0.294147</td>\n",
       "      <td>-0.039832</td>\n",
       "      <td>-0.392053</td>\n",
       "      <td>-0.458610</td>\n",
       "      <td>0.237367</td>\n",
       "      <td>-0.181718</td>\n",
       "      <td>-0.223689</td>\n",
       "      <td>0.047916</td>\n",
       "      <td>-0.251913</td>\n",
       "      <td>-0.228134</td>\n",
       "      <td>-0.246961</td>\n",
       "      <td>-0.226237</td>\n",
       "      <td>-0.280484</td>\n",
       "      <td>-0.411559</td>\n",
       "      <td>-0.246129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.967579</td>\n",
       "      <td>0.642245</td>\n",
       "      <td>0.471634</td>\n",
       "      <td>0.485178</td>\n",
       "      <td>0.440402</td>\n",
       "      <td>0.630687</td>\n",
       "      <td>0.127866</td>\n",
       "      <td>0.295396</td>\n",
       "      <td>0.829445</td>\n",
       "      <td>0.453112</td>\n",
       "      <td>0.486852</td>\n",
       "      <td>0.701148</td>\n",
       "      <td>0.672528</td>\n",
       "      <td>0.521896</td>\n",
       "      <td>0.499841</td>\n",
       "      <td>0.342543</td>\n",
       "      <td>0.465452</td>\n",
       "      <td>0.095927</td>\n",
       "      <td>0.454249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.256426</td>\n",
       "      <td>2.362191</td>\n",
       "      <td>4.001556</td>\n",
       "      <td>4.376492</td>\n",
       "      <td>3.632866</td>\n",
       "      <td>3.588374</td>\n",
       "      <td>4.287221</td>\n",
       "      <td>3.876924</td>\n",
       "      <td>3.087750</td>\n",
       "      <td>4.156286</td>\n",
       "      <td>3.644809</td>\n",
       "      <td>2.875339</td>\n",
       "      <td>4.370294</td>\n",
       "      <td>3.672025</td>\n",
       "      <td>3.785767</td>\n",
       "      <td>4.599771</td>\n",
       "      <td>3.946484</td>\n",
       "      <td>5.678281</td>\n",
       "      <td>3.816063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               GP         MIN         PTS         FGM         FGA         FG%  \\\n",
       "count  328.000000  328.000000  328.000000  328.000000  328.000000  328.000000   \n",
       "mean     0.018258    0.000382    0.009606    0.010072   -0.002412    0.033611   \n",
       "std      1.011584    0.980169    0.984359    0.999085    0.979138    0.983559   \n",
       "min     -2.614125   -1.605515   -1.325739   -1.338875   -1.311215   -3.338948   \n",
       "25%     -0.722176   -0.819860   -0.689292   -0.730857   -0.696736   -0.595169   \n",
       "50%      0.216577   -0.191944   -0.264995   -0.305245   -0.294147   -0.039832   \n",
       "75%      0.967579    0.642245    0.471634    0.485178    0.440402    0.630687   \n",
       "max      1.256426    2.362191    4.001556    4.376492    3.632866    3.588374   \n",
       "\n",
       "          3P Made         3PA         3P%         FTM         FTA         FT%  \\\n",
       "count  328.000000  328.000000  328.000000  328.000000  328.000000  328.000000   \n",
       "mean    -0.056008   -0.056033   -0.000789    0.031505    0.040357   -0.046638   \n",
       "std      0.905094    0.900421    1.005049    0.960512    0.959364    1.047490   \n",
       "min     -0.652013   -0.741363   -1.228266   -1.239768   -1.328974   -3.822727   \n",
       "25%     -0.652013   -0.741363   -1.228266   -0.604938   -0.618433   -0.615065   \n",
       "50%     -0.392053   -0.458610    0.237367   -0.181718   -0.223689    0.047916   \n",
       "75%      0.127866    0.295396    0.829445    0.453112    0.486852    0.701148   \n",
       "max      4.287221    3.876924    3.087750    4.156286    3.644809    2.875339   \n",
       "\n",
       "             OREB        DREB         REB         AST         STL         BLK  \\\n",
       "count  328.000000  328.000000  328.000000  328.000000  328.000000  328.000000   \n",
       "mean     0.047645    0.002592    0.015634    0.018637    0.022742   -0.039454   \n",
       "std      1.015325    0.973646    0.992538    0.958121    0.992125    0.987205   \n",
       "min     -1.176354   -1.278177   -1.292482   -1.053552   -1.523710   -0.919046   \n",
       "25%     -0.681118   -0.753156   -0.744828   -0.639894   -0.777774   -0.665303   \n",
       "50%     -0.251913   -0.228134   -0.246961   -0.226237   -0.280484   -0.411559   \n",
       "75%      0.672528    0.521896    0.499841    0.342543    0.465452    0.095927   \n",
       "max      4.370294    3.672025    3.785767    4.599771    3.946484    5.678281   \n",
       "\n",
       "              TOV  \n",
       "count  328.000000  \n",
       "mean     0.037866  \n",
       "std      0.953656  \n",
       "min     -1.506809  \n",
       "25%     -0.666356  \n",
       "50%     -0.246129  \n",
       "75%      0.454249  \n",
       "max      3.816063  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 67  62]\n",
      " [ 28 171]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.52      0.60       129\n",
      "         1.0       0.73      0.86      0.79       199\n",
      "\n",
      "    accuracy                           0.73       328\n",
      "   macro avg       0.72      0.69      0.69       328\n",
      "weighted avg       0.72      0.73      0.72       328\n",
      "\n",
      "Score: \n",
      " 71.65\n",
      "Test Score: \n",
      " 72.56\n",
      "Accuracy: \n",
      " 0.725609756097561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_as_af =  LogisticRegression(random_state = 11)\n",
    "lr_as_af.fit(X_train, y_train)\n",
    "y_pred = lr_as_af.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "lr_as_af_score = round(lr_as_af.score(X_train, y_train) * 100, 2)\n",
    "lr_as_af_score_test = round(lr_as_af.score(X_test, y_test) * 100, 2)\n",
    "print('Score: \\n', lr_as_af_score)\n",
    "print('Test Score: \\n', lr_as_af_score_test)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 800 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2814 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done 3296 tasks      | elapsed:   31.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.615848211066026, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l1', 'random_state': 11, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} \n",
      "\n",
      "Model accuracy is 0.7164634146341463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed:  1.0min finished\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "param_grid = [\n",
    "    {'penalty' : ['l1', 'l2'],\n",
    "    'C': np.logspace(-4, 4, 20),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000,2500, 5000]}\n",
    "]\n",
    "\n",
    "lr_as_af_gscv = GridSearchCV(lr_as_af, param_grid = param_grid, cv = kfold, verbose=True, n_jobs=-1)\n",
    "best_lr_as_af_gscv = lr_as_af_gscv.fit(X_train, y_train)\n",
    "\n",
    "print(best_lr_as_af_gscv.best_estimator_.get_params(), '\\n')\n",
    "print('Model accuracy is',best_lr_as_af_gscv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy          :  0.7164634146341463 \n",
      " Balanced Accuracy :  0.7054919312857887 \n",
      " Precision         :  0.8341708542713567 \n",
      " Average Precision :  0.7956363947950414 \n",
      " F1-Score          :  0.7811764705882354 \n",
      " Recall            :  0.7345132743362832 \n",
      " ROC-AUC           :  0.7850103229324921 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.68      0.60       102\n",
      "         1.0       0.83      0.73      0.78       226\n",
      "\n",
      "    accuracy                           0.72       328\n",
      "   macro avg       0.68      0.71      0.69       328\n",
      "weighted avg       0.74      0.72      0.72       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "probs = best_lr_as_af_gscv.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "classes = best_lr_as_af_gscv.predict(X_test)\n",
    "    \n",
    "accuracy = metrics.accuracy_score(classes, y_test)\n",
    "    \n",
    "balanced_accuracy = metrics.balanced_accuracy_score(classes, y_test)\n",
    "\n",
    "precision = metrics.precision_score(classes, y_test)\n",
    "    \n",
    "average_precision = metrics.average_precision_score(classes, y_test)\n",
    "    \n",
    "f1_score = metrics.f1_score(classes, y_test)\n",
    "    \n",
    "recall = metrics.recall_score(classes, y_test)\n",
    "\n",
    "print (\"\\n Accuracy          : \", accuracy, \"\\n Balanced Accuracy : \", balanced_accuracy, \"\\n Precision         : \", precision, \"\\n Average Precision : \", average_precision, \"\\n F1-Score          : \", f1_score, \"\\n Recall            : \", recall, \"\\n ROC-AUC           : \", roc_auc, \"\\n\")\n",
    "\n",
    "print(metrics.classification_report(classes, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.615848211066026, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 11, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} \n",
      "\n",
      "Model accuracy is 0.725609756097561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.5s finished\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "param_grid = [\n",
    "    {'penalty' : ['l1', 'l2'],\n",
    "    'C': np.logspace(-4, 4, 20),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000,2500, 5000]}\n",
    "]\n",
    "\n",
    "lr_as_af_rscv = RandomizedSearchCV(lr_as_af, param_distributions = param_grid, cv = kfold, verbose=True, n_jobs=-1, random_state = 11)\n",
    "best_lr_as_af_rscv = lr_as_af_rscv.fit(X_train, y_train)\n",
    "\n",
    "print(best_lr_as_af_rscv.best_estimator_.get_params(), '\\n')\n",
    "print('Model accuracy is',best_lr_as_af_rscv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy          :  0.725609756097561 \n",
      " Balanced Accuracy :  0.7184808318828937 \n",
      " Precision         :  0.8542713567839196 \n",
      " Average Precision :  0.8146601580386358 \n",
      " F1-Score          :  0.7906976744186045 \n",
      " Recall            :  0.7359307359307359 \n",
      " ROC-AUC           :  0.786217911261735 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.70      0.60        97\n",
      "         1.0       0.85      0.74      0.79       231\n",
      "\n",
      "    accuracy                           0.73       328\n",
      "   macro avg       0.69      0.72      0.70       328\n",
      "weighted avg       0.76      0.73      0.73       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "probs = best_lr_as_af_rscv.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "classes = best_lr_as_af_rscv.predict(X_test)\n",
    "    \n",
    "accuracy = metrics.accuracy_score(classes, y_test)\n",
    "    \n",
    "balanced_accuracy = metrics.balanced_accuracy_score(classes, y_test)\n",
    "\n",
    "precision = metrics.precision_score(classes, y_test)\n",
    "    \n",
    "average_precision = metrics.average_precision_score(classes, y_test)\n",
    "    \n",
    "f1_score = metrics.f1_score(classes, y_test)\n",
    "    \n",
    "recall = metrics.recall_score(classes, y_test)\n",
    "\n",
    "print (\"\\n Accuracy          : \", accuracy, \"\\n Balanced Accuracy : \", balanced_accuracy, \"\\n Precision         : \", precision, \"\\n Average Precision : \", average_precision, \"\\n F1-Score          : \", f1_score, \"\\n Recall            : \", recall, \"\\n ROC-AUC           : \", roc_auc, \"\\n\")\n",
    "\n",
    "print(metrics.classification_report(classes, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:06<00:00, 15.67trial/s, best loss: -0.7094064021547706]\n",
      "best:\n",
      "{'C': 0.43307347584912836, 'max_iter': 3, 'penalty': 1, 'solver': 4}\n",
      "Accuracy :  70.94064021547706\n"
     ]
    }
   ],
   "source": [
    "def f(params):\n",
    "    acc = hyperopt_train_test(params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "def hyperopt_train_test(params):\n",
    "    lr_as_af_bo = LogisticRegression(**params, random_state = 11)\n",
    "    return sklearn.model_selection.cross_val_score(lr_as_af_bo, X_train, y_train).mean()\n",
    "\n",
    "param_grid = {\n",
    "    'C': hp.uniform('C', 0, 20),\n",
    "    'penalty': hp.choice('penalty', ['l1', 'l2']),\n",
    "    'solver': hp.choice('solver', ['lbfgs','newton-cg','liblinear','sag','saga']),\n",
    "    'max_iter' : hp.choice('max_iter', [100, 1000,2500, 5000])\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(f, param_grid, algo=tpe.suggest, max_evals=100, trials=trials)\n",
    "print('best:')\n",
    "print(best)\n",
    "print(\"Accuracy : \", -trials.best_trial['result']['loss']*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GP', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3P Made', '3PA', '3P%', 'FTM',\n",
       "       'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[['FGM', 'REB', 'FTM', 'FTA', 'GP', 'MIN', 'TOV', 'FG%', 'DREB', 'AST']]\n",
    "X_test = X_test[['FGM', 'REB', 'FTM', 'FTA', 'GP', 'MIN', 'TOV', 'FG%', 'DREB', 'AST']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 66  63]\n",
      " [ 34 165]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.51      0.58       129\n",
      "         1.0       0.72      0.83      0.77       199\n",
      "\n",
      "    accuracy                           0.70       328\n",
      "   macro avg       0.69      0.67      0.67       328\n",
      "weighted avg       0.70      0.70      0.70       328\n",
      "\n",
      "Score: \n",
      " 70.83\n",
      "Test Score: \n",
      " 70.43\n",
      "Accuracy: \n",
      " 0.7042682926829268\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_bs_tf =  LogisticRegression(random_state = 11)\n",
    "lr_bs_tf.fit(X_train, y_train)\n",
    "y_pred = lr_bs_tf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "lr_bs_tf_score = round(lr_bs_tf.score(X_train, y_train) * 100, 2)\n",
    "lr_bs_tf_score_test = round(lr_bs_tf.score(X_test, y_test) * 100, 2)\n",
    "print('Score: \\n', lr_bs_tf_score)\n",
    "print('Test Score: \\n', lr_bs_tf_score_test)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 800 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 964 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1592 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2456 tasks      | elapsed:   43.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3468 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 4.281332398719396, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 2500, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 11, 'solver': 'sag', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} \n",
      "\n",
      "Model accuracy is 0.7134146341463414\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "param_grid = [\n",
    "    {'penalty' : ['l1', 'l2'],\n",
    "    'C': np.logspace(-4, 4, 20),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000,2500, 5000]}\n",
    "]\n",
    "\n",
    "lr_bs_tf_gscv = GridSearchCV(lr_bs_tf, param_grid = param_grid, cv = kfold, verbose=True, n_jobs=-1)\n",
    "best_lr_bs_tf_gscv = lr_bs_tf_gscv.fit(X_train, y_train)\n",
    "\n",
    "print(best_lr_bs_tf_gscv.best_estimator_.get_params(), '\\n')\n",
    "print('Model accuracy is',best_lr_bs_tf_gscv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy          :  0.7134146341463414 \n",
      " Balanced Accuracy :  0.7022724298861605 \n",
      " Precision         :  0.8341708542713567 \n",
      " Average Precision :  0.7959860142012306 \n",
      " F1-Score          :  0.7793427230046948 \n",
      " Recall            :  0.7312775330396476 \n",
      " ROC-AUC           :  0.7805695142378559 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.67      0.59       101\n",
      "         1.0       0.83      0.73      0.78       227\n",
      "\n",
      "    accuracy                           0.71       328\n",
      "   macro avg       0.68      0.70      0.69       328\n",
      "weighted avg       0.74      0.71      0.72       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "probs = best_lr_bs_tf_gscv.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "classes = best_lr_bs_tf_gscv.predict(X_test)\n",
    "    \n",
    "accuracy = metrics.accuracy_score(classes, y_test)\n",
    "    \n",
    "balanced_accuracy = metrics.balanced_accuracy_score(classes, y_test)\n",
    "\n",
    "precision = metrics.precision_score(classes, y_test)\n",
    "    \n",
    "average_precision = metrics.average_precision_score(classes, y_test)\n",
    "    \n",
    "f1_score = metrics.f1_score(classes, y_test)\n",
    "    \n",
    "recall = metrics.recall_score(classes, y_test)\n",
    "\n",
    "print (\"\\n Accuracy          : \", accuracy, \"\\n Balanced Accuracy : \", balanced_accuracy, \"\\n Precision         : \", precision, \"\\n Average Precision : \", average_precision, \"\\n F1-Score          : \", f1_score, \"\\n Recall            : \", recall, \"\\n ROC-AUC           : \", roc_auc, \"\\n\")\n",
    "\n",
    "print(metrics.classification_report(classes, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  50 | elapsed:    0.9s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10000.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 5000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 11, 'solver': 'sag', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} \n",
      "\n",
      "Model accuracy is 0.7103658536585366\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "param_grid = [\n",
    "    {'penalty' : ['l1', 'l2'],\n",
    "    'C': np.logspace(-4, 4, 20),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000,2500, 5000]}\n",
    "]\n",
    "\n",
    "lr_bs_tf_rscv = RandomizedSearchCV(lr_bs_tf, param_distributions = param_grid, cv = kfold, verbose=True, n_jobs=-1, random_state = 11)\n",
    "best_lr_bs_tf_rscv = lr_bs_tf_rscv.fit(X_train, y_train)\n",
    "\n",
    "print(best_lr_bs_tf_rscv.best_estimator_.get_params(), '\\n')\n",
    "print('Model accuracy is',best_lr_bs_tf_rscv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy          :  0.7103658536585366 \n",
      " Balanced Accuracy :  0.698377581120944 \n",
      " Precision         :  0.8291457286432161 \n",
      " Average Precision :  0.7913253673938438 \n",
      " F1-Score          :  0.7764705882352942 \n",
      " Recall            :  0.7300884955752213 \n",
      " ROC-AUC           :  0.7813096490202953 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.67      0.59       102\n",
      "         1.0       0.83      0.73      0.78       226\n",
      "\n",
      "    accuracy                           0.71       328\n",
      "   macro avg       0.68      0.70      0.68       328\n",
      "weighted avg       0.74      0.71      0.72       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "probs = best_lr_bs_tf_rscv.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "classes = best_lr_bs_tf_rscv.predict(X_test)\n",
    "    \n",
    "accuracy = metrics.accuracy_score(classes, y_test)\n",
    "    \n",
    "balanced_accuracy = metrics.balanced_accuracy_score(classes, y_test)\n",
    "\n",
    "precision = metrics.precision_score(classes, y_test)\n",
    "    \n",
    "average_precision = metrics.average_precision_score(classes, y_test)\n",
    "    \n",
    "f1_score = metrics.f1_score(classes, y_test)\n",
    "    \n",
    "recall = metrics.recall_score(classes, y_test)\n",
    "\n",
    "print (\"\\n Accuracy          : \", accuracy, \"\\n Balanced Accuracy : \", balanced_accuracy, \"\\n Precision         : \", precision, \"\\n Average Precision : \", average_precision, \"\\n F1-Score          : \", f1_score, \"\\n Recall            : \", recall, \"\\n ROC-AUC           : \", roc_auc, \"\\n\")\n",
    "\n",
    "print(metrics.classification_report(classes, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:24<00:00,  4.10trial/s, best loss: -0.710426810318036]\n",
      "best:\n",
      "{'C': 3.9802952318528035, 'max_iter': 3, 'penalty': 1, 'solver': 3}\n",
      "Accuracy :  71.0426810318036\n"
     ]
    }
   ],
   "source": [
    "def f(params):\n",
    "    acc = hyperopt_train_test(params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "def hyperopt_train_test(params):\n",
    "    lr_bs_tf_bo = LogisticRegression(**params, random_state = 11)\n",
    "    return sklearn.model_selection.cross_val_score(lr_bs_tf_bo, X_train, y_train).mean()\n",
    "\n",
    "param_grid = {\n",
    "    'C': hp.uniform('C', 0, 20),\n",
    "    'penalty': hp.choice('penalty', ['l1', 'l2']),\n",
    "    'solver': hp.choice('solver', ['lbfgs','newton-cg','liblinear','sag','saga']),\n",
    "    'max_iter' : hp.choice('max_iter', [100, 1000,2500, 5000])\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(f, param_grid, algo=tpe.suggest, max_evals=100, trials=trials)\n",
    "print('best:')\n",
    "print(best)\n",
    "print(\"Accuracy : \", -trials.best_trial['result']['loss']*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GP', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3P Made', '3PA', '3P%', 'FTM',\n",
       "       'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[['FGM', 'REB', 'FTM', 'FTA', 'GP', 'MIN', 'TOV', 'FG%', 'DREB', 'AST']]\n",
    "X_test = X_test[['FGM', 'REB', 'FTM', 'FTA', 'GP', 'MIN', 'TOV', 'FG%', 'DREB', 'AST']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = X_train.mean()\n",
    "train_std = X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FGM</th>\n",
       "      <th>REB</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>TOV</th>\n",
       "      <th>FG%</th>\n",
       "      <th>DREB</th>\n",
       "      <th>AST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.451827e-16</td>\n",
       "      <td>-1.996314e-15</td>\n",
       "      <td>-1.836550e-15</td>\n",
       "      <td>1.356695e-15</td>\n",
       "      <td>3.384826e-17</td>\n",
       "      <td>1.358218e-15</td>\n",
       "      <td>-7.536880e-17</td>\n",
       "      <td>-1.311665e-14</td>\n",
       "      <td>1.510535e-15</td>\n",
       "      <td>6.514662e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.399677e+00</td>\n",
       "      <td>-1.342269e+00</td>\n",
       "      <td>-1.239768e+00</td>\n",
       "      <td>-1.328974e+00</td>\n",
       "      <td>-2.845202e+00</td>\n",
       "      <td>-1.629782e+00</td>\n",
       "      <td>-1.506809e+00</td>\n",
       "      <td>-2.812406e+00</td>\n",
       "      <td>-1.353180e+00</td>\n",
       "      <td>-1.053552e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.308572e-01</td>\n",
       "      <td>-7.448281e-01</td>\n",
       "      <td>-7.107428e-01</td>\n",
       "      <td>-6.973822e-01</td>\n",
       "      <td>-7.655035e-01</td>\n",
       "      <td>-8.168270e-01</td>\n",
       "      <td>-6.663555e-01</td>\n",
       "      <td>-6.568735e-01</td>\n",
       "      <td>-7.531557e-01</td>\n",
       "      <td>-6.398944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.052447e-01</td>\n",
       "      <td>-2.469605e-01</td>\n",
       "      <td>-2.875229e-01</td>\n",
       "      <td>-2.236886e-01</td>\n",
       "      <td>1.010378e-01</td>\n",
       "      <td>-1.737431e-01</td>\n",
       "      <td>-2.461287e-01</td>\n",
       "      <td>1.304316e-03</td>\n",
       "      <td>-2.281343e-01</td>\n",
       "      <td>-2.951796e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.851784e-01</td>\n",
       "      <td>4.500541e-01</td>\n",
       "      <td>3.473070e-01</td>\n",
       "      <td>4.079028e-01</td>\n",
       "      <td>9.675790e-01</td>\n",
       "      <td>6.392119e-01</td>\n",
       "      <td>4.542492e-01</td>\n",
       "      <td>6.101188e-01</td>\n",
       "      <td>4.468932e-01</td>\n",
       "      <td>2.563641e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.890078e+00</td>\n",
       "      <td>4.632142e+00</td>\n",
       "      <td>5.002726e+00</td>\n",
       "      <td>5.302736e+00</td>\n",
       "      <td>1.256426e+00</td>\n",
       "      <td>2.835404e+00</td>\n",
       "      <td>4.236290e+00</td>\n",
       "      <td>3.637737e+00</td>\n",
       "      <td>5.097083e+00</td>\n",
       "      <td>5.358143e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                FGM           REB           FTM           FTA            GP  \\\n",
       "count  9.840000e+02  9.840000e+02  9.840000e+02  9.840000e+02  9.840000e+02   \n",
       "mean   5.451827e-16 -1.996314e-15 -1.836550e-15  1.356695e-15  3.384826e-17   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.399677e+00 -1.342269e+00 -1.239768e+00 -1.328974e+00 -2.845202e+00   \n",
       "25%   -7.308572e-01 -7.448281e-01 -7.107428e-01 -6.973822e-01 -7.655035e-01   \n",
       "50%   -3.052447e-01 -2.469605e-01 -2.875229e-01 -2.236886e-01  1.010378e-01   \n",
       "75%    4.851784e-01  4.500541e-01  3.473070e-01  4.079028e-01  9.675790e-01   \n",
       "max    3.890078e+00  4.632142e+00  5.002726e+00  5.302736e+00  1.256426e+00   \n",
       "\n",
       "                MIN           TOV           FG%          DREB           AST  \n",
       "count  9.840000e+02  9.840000e+02  9.840000e+02  9.840000e+02  9.840000e+02  \n",
       "mean   1.358218e-15 -7.536880e-17 -1.311665e-14  1.510535e-15  6.514662e-16  \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "min   -1.629782e+00 -1.506809e+00 -2.812406e+00 -1.353180e+00 -1.053552e+00  \n",
       "25%   -8.168270e-01 -6.663555e-01 -6.568735e-01 -7.531557e-01 -6.398944e-01  \n",
       "50%   -1.737431e-01 -2.461287e-01  1.304316e-03 -2.281343e-01 -2.951796e-01  \n",
       "75%    6.392119e-01  4.542492e-01  6.101188e-01  4.468932e-01  2.563641e-01  \n",
       "max    2.835404e+00  4.236290e+00  3.637737e+00  5.097083e+00  5.358143e+00  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = (X_test - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FGM</th>\n",
       "      <th>REB</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>TOV</th>\n",
       "      <th>FG%</th>\n",
       "      <th>DREB</th>\n",
       "      <th>AST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.010072</td>\n",
       "      <td>0.015634</td>\n",
       "      <td>0.031505</td>\n",
       "      <td>0.040357</td>\n",
       "      <td>0.018258</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.037866</td>\n",
       "      <td>0.033611</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>0.018637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.999085</td>\n",
       "      <td>0.992538</td>\n",
       "      <td>0.960512</td>\n",
       "      <td>0.959364</td>\n",
       "      <td>1.011584</td>\n",
       "      <td>0.980169</td>\n",
       "      <td>0.953656</td>\n",
       "      <td>0.983559</td>\n",
       "      <td>0.973646</td>\n",
       "      <td>0.958121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.338875</td>\n",
       "      <td>-1.292482</td>\n",
       "      <td>-1.239768</td>\n",
       "      <td>-1.328974</td>\n",
       "      <td>-2.614125</td>\n",
       "      <td>-1.605515</td>\n",
       "      <td>-1.506809</td>\n",
       "      <td>-3.338948</td>\n",
       "      <td>-1.278177</td>\n",
       "      <td>-1.053552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.730857</td>\n",
       "      <td>-0.744828</td>\n",
       "      <td>-0.604938</td>\n",
       "      <td>-0.618433</td>\n",
       "      <td>-0.722176</td>\n",
       "      <td>-0.819860</td>\n",
       "      <td>-0.666356</td>\n",
       "      <td>-0.595169</td>\n",
       "      <td>-0.753156</td>\n",
       "      <td>-0.639894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.305245</td>\n",
       "      <td>-0.246961</td>\n",
       "      <td>-0.181718</td>\n",
       "      <td>-0.223689</td>\n",
       "      <td>0.216577</td>\n",
       "      <td>-0.191944</td>\n",
       "      <td>-0.246129</td>\n",
       "      <td>-0.039832</td>\n",
       "      <td>-0.228134</td>\n",
       "      <td>-0.226237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.485178</td>\n",
       "      <td>0.499841</td>\n",
       "      <td>0.453112</td>\n",
       "      <td>0.486852</td>\n",
       "      <td>0.967579</td>\n",
       "      <td>0.642245</td>\n",
       "      <td>0.454249</td>\n",
       "      <td>0.630687</td>\n",
       "      <td>0.521896</td>\n",
       "      <td>0.342543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.376492</td>\n",
       "      <td>3.785767</td>\n",
       "      <td>4.156286</td>\n",
       "      <td>3.644809</td>\n",
       "      <td>1.256426</td>\n",
       "      <td>2.362191</td>\n",
       "      <td>3.816063</td>\n",
       "      <td>3.588374</td>\n",
       "      <td>3.672025</td>\n",
       "      <td>4.599771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              FGM         REB         FTM         FTA          GP         MIN  \\\n",
       "count  328.000000  328.000000  328.000000  328.000000  328.000000  328.000000   \n",
       "mean     0.010072    0.015634    0.031505    0.040357    0.018258    0.000382   \n",
       "std      0.999085    0.992538    0.960512    0.959364    1.011584    0.980169   \n",
       "min     -1.338875   -1.292482   -1.239768   -1.328974   -2.614125   -1.605515   \n",
       "25%     -0.730857   -0.744828   -0.604938   -0.618433   -0.722176   -0.819860   \n",
       "50%     -0.305245   -0.246961   -0.181718   -0.223689    0.216577   -0.191944   \n",
       "75%      0.485178    0.499841    0.453112    0.486852    0.967579    0.642245   \n",
       "max      4.376492    3.785767    4.156286    3.644809    1.256426    2.362191   \n",
       "\n",
       "              TOV         FG%        DREB         AST  \n",
       "count  328.000000  328.000000  328.000000  328.000000  \n",
       "mean     0.037866    0.033611    0.002592    0.018637  \n",
       "std      0.953656    0.983559    0.973646    0.958121  \n",
       "min     -1.506809   -3.338948   -1.278177   -1.053552  \n",
       "25%     -0.666356   -0.595169   -0.753156   -0.639894  \n",
       "50%     -0.246129   -0.039832   -0.228134   -0.226237  \n",
       "75%      0.454249    0.630687    0.521896    0.342543  \n",
       "max      3.816063    3.588374    3.672025    4.599771  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 69  60]\n",
      " [ 32 167]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.53      0.60       129\n",
      "         1.0       0.74      0.84      0.78       199\n",
      "\n",
      "    accuracy                           0.72       328\n",
      "   macro avg       0.71      0.69      0.69       328\n",
      "weighted avg       0.72      0.72      0.71       328\n",
      "\n",
      "Score: \n",
      " 72.15\n",
      "Test Score: \n",
      " 71.95\n",
      "Accuracy: \n",
      " 0.7195121951219512\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_as_tf =  LogisticRegression(random_state = 11)\n",
    "lr_as_tf.fit(X_train, y_train)\n",
    "y_pred = lr_as_tf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "lr_as_tf_score = round(lr_as_tf.score(X_train, y_train) * 100, 2)\n",
    "lr_as_tf_score_test = round(lr_as_tf.score(X_test, y_test) * 100, 2)\n",
    "print('Score: \\n', lr_as_tf_score)\n",
    "print('Test Score: \\n', lr_as_tf_score_test)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 800 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 3644 tasks      | elapsed:    7.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 11.288378916846883, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 11, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} \n",
      "\n",
      "Model accuracy is 0.7164634146341463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed:    8.5s finished\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "param_grid = [\n",
    "    {'penalty' : ['l1', 'l2'],\n",
    "    'C': np.logspace(-4, 4, 20),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000,2500, 5000]}\n",
    "]\n",
    "\n",
    "lr_as_tf_gscv = GridSearchCV(lr_as_tf, param_grid = param_grid, cv = kfold, verbose=True, n_jobs=-1)\n",
    "best_lr_as_tf_gscv = lr_as_tf_gscv.fit(X_train, y_train)\n",
    "\n",
    "print(best_lr_as_tf_gscv.best_estimator_.get_params(), '\\n')\n",
    "print('Model accuracy is',best_lr_as_tf_gscv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy          :  0.7164634146341463 \n",
      " Balanced Accuracy :  0.7048420329670331 \n",
      " Precision         :  0.8291457286432161 \n",
      " Average Precision :  0.7906327149685712 \n",
      " F1-Score          :  0.7801418439716313 \n",
      " Recall            :  0.7366071428571429 \n",
      " ROC-AUC           :  0.7801799696155195 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.67      0.60       104\n",
      "         1.0       0.83      0.74      0.78       224\n",
      "\n",
      "    accuracy                           0.72       328\n",
      "   macro avg       0.69      0.70      0.69       328\n",
      "weighted avg       0.74      0.72      0.72       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "probs = best_lr_as_tf_gscv.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "classes = best_lr_as_tf_gscv.predict(X_test)\n",
    "    \n",
    "accuracy = metrics.accuracy_score(classes, y_test)\n",
    "    \n",
    "balanced_accuracy = metrics.balanced_accuracy_score(classes, y_test)\n",
    "\n",
    "precision = metrics.precision_score(classes, y_test)\n",
    "    \n",
    "average_precision = metrics.average_precision_score(classes, y_test)\n",
    "    \n",
    "f1_score = metrics.f1_score(classes, y_test)\n",
    "    \n",
    "recall = metrics.recall_score(classes, y_test)\n",
    "\n",
    "print (\"\\n Accuracy          : \", accuracy, \"\\n Balanced Accuracy : \", balanced_accuracy, \"\\n Precision         : \", precision, \"\\n Average Precision : \", average_precision, \"\\n F1-Score          : \", f1_score, \"\\n Recall            : \", recall, \"\\n ROC-AUC           : \", roc_auc, \"\\n\")\n",
    "\n",
    "print(metrics.classification_report(classes, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "{'C': 10000.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 5000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 11, 'solver': 'sag', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} \n",
      "\n",
      "Model accuracy is 0.7134146341463414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "param_grid = [\n",
    "    {'penalty' : ['l1', 'l2'],\n",
    "    'C': np.logspace(-4, 4, 20),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000,2500, 5000]}\n",
    "]\n",
    "\n",
    "lr_as_tf_rscv = RandomizedSearchCV(lr_as_tf, param_distributions = param_grid, cv = kfold, verbose=True, n_jobs=-1, random_state = 11)\n",
    "best_lr_as_tf_rscv = lr_as_tf_rscv.fit(X_train, y_train)\n",
    "\n",
    "print(best_lr_as_tf_rscv.best_estimator_.get_params(), '\\n')\n",
    "print('Model accuracy is',best_lr_as_tf_rscv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy          :  0.7134146341463414 \n",
      " Balanced Accuracy :  0.7016181229773463 \n",
      " Precision         :  0.8291457286432161 \n",
      " Average Precision :  0.7909670302733178 \n",
      " F1-Score          :  0.7783018867924528 \n",
      " Recall            :  0.7333333333333333 \n",
      " ROC-AUC           :  0.7801799696155195 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.67      0.59       103\n",
      "         1.0       0.83      0.73      0.78       225\n",
      "\n",
      "    accuracy                           0.71       328\n",
      "   macro avg       0.68      0.70      0.69       328\n",
      "weighted avg       0.74      0.71      0.72       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "probs = best_lr_as_tf_rscv.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "classes = best_lr_as_tf_rscv.predict(X_test)\n",
    "    \n",
    "accuracy = metrics.accuracy_score(classes, y_test)\n",
    "    \n",
    "balanced_accuracy = metrics.balanced_accuracy_score(classes, y_test)\n",
    "\n",
    "precision = metrics.precision_score(classes, y_test)\n",
    "    \n",
    "average_precision = metrics.average_precision_score(classes, y_test)\n",
    "    \n",
    "f1_score = metrics.f1_score(classes, y_test)\n",
    "    \n",
    "recall = metrics.recall_score(classes, y_test)\n",
    "\n",
    "print (\"\\n Accuracy          : \", accuracy, \"\\n Balanced Accuracy : \", balanced_accuracy, \"\\n Precision         : \", precision, \"\\n Average Precision : \", average_precision, \"\\n F1-Score          : \", f1_score, \"\\n Recall            : \", recall, \"\\n ROC-AUC           : \", roc_auc, \"\\n\")\n",
    "\n",
    "print(metrics.classification_report(classes, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:03<00:00, 29.89trial/s, best loss: -0.708396353465244]\n",
      "best:\n",
      "{'C': 16.54547839312792, 'max_iter': 0, 'penalty': 1, 'solver': 0}\n",
      "Accuracy :  70.8396353465244\n"
     ]
    }
   ],
   "source": [
    "def f(params):\n",
    "    acc = hyperopt_train_test(params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "def hyperopt_train_test(params):\n",
    "    lr_as_tf_bo = LogisticRegression(**params, random_state = 11)\n",
    "    return sklearn.model_selection.cross_val_score(lr_as_tf_bo, X_train, y_train).mean()\n",
    "\n",
    "param_grid = {\n",
    "    'C': hp.uniform('C', 0, 20),\n",
    "    'penalty': hp.choice('penalty', ['l1', 'l2']),\n",
    "    'solver': hp.choice('solver', ['lbfgs','newton-cg','liblinear','sag','saga']),\n",
    "    'max_iter' : hp.choice('max_iter', [100, 1000,2500, 5000])\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(f, param_grid, algo=tpe.suggest, max_evals=100, trials=trials)\n",
    "print('best:')\n",
    "print(best)\n",
    "print(\"Accuracy : \", -trials.best_trial['result']['loss']*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GP', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3P Made', '3PA', '3P%', 'FTM',\n",
       "       'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[['GP', '3P Made', '3PA', 'AST', 'BLK']]\n",
    "X_test = X_test[['GP', '3P Made', '3PA', 'AST', 'BLK']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - Naive Bayes Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 92  37]\n",
      " [ 54 145]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.71      0.67       129\n",
      "         1.0       0.80      0.73      0.76       199\n",
      "\n",
      "    accuracy                           0.72       328\n",
      "   macro avg       0.71      0.72      0.72       328\n",
      "weighted avg       0.73      0.72      0.72       328\n",
      "\n",
      "Score: \n",
      " 66.57\n",
      "Test Score: \n",
      " 72.26\n",
      "Accuracy: \n",
      " 0.7225609756097561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb_bs_ff =  GaussianNB()\n",
    "gnb_bs_ff.fit(X_train, y_train)\n",
    "y_pred = gnb_bs_ff.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "gnb_bs_ff_score = round(gnb_bs_ff.score(X_train, y_train) * 100, 2)\n",
    "gnb_bs_ff_score_test = round(gnb_bs_ff.score(X_test, y_test) * 100, 2)\n",
    "print('Score: \\n', gnb_bs_ff_score)\n",
    "print('Test Score: \\n', gnb_bs_ff_score_test)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'priors': None, 'var_smoothing': 0.01519911082952933} \n",
      "\n",
      "Model accuracy is 0.6890243902439024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "param_grid = [\n",
    "    {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "]\n",
    "\n",
    "gnb_bs_ff_gscv = GridSearchCV(gnb_bs_ff, param_grid = param_grid, cv = kfold, verbose=True, n_jobs=-1)\n",
    "best_gnb_bs_ff_gscv = gnb_bs_ff_gscv.fit(X_train, y_train)\n",
    "\n",
    "print(best_gnb_bs_ff_gscv.best_estimator_.get_params(), '\\n')\n",
    "print('Model accuracy is',best_gnb_bs_ff_gscv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy          :  0.6890243902439024 \n",
      " Balanced Accuracy :  0.6740770146883683 \n",
      " Precision         :  0.8190954773869347 \n",
      " Average Precision :  0.7842438039596212 \n",
      " F1-Score          :  0.7616822429906541 \n",
      " Recall            :  0.7117903930131004 \n",
      " ROC-AUC           :  0.762494643761443 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.64      0.55        99\n",
      "         1.0       0.82      0.71      0.76       229\n",
      "\n",
      "    accuracy                           0.69       328\n",
      "   macro avg       0.65      0.67      0.66       328\n",
      "weighted avg       0.72      0.69      0.70       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "probs = best_gnb_bs_ff_gscv.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "classes = best_gnb_bs_ff_gscv.predict(X_test)\n",
    "    \n",
    "accuracy = metrics.accuracy_score(classes, y_test)\n",
    "    \n",
    "balanced_accuracy = metrics.balanced_accuracy_score(classes, y_test)\n",
    "\n",
    "precision = metrics.precision_score(classes, y_test)\n",
    "    \n",
    "average_precision = metrics.average_precision_score(classes, y_test)\n",
    "    \n",
    "f1_score = metrics.f1_score(classes, y_test)\n",
    "    \n",
    "recall = metrics.recall_score(classes, y_test)\n",
    "\n",
    "print (\"\\n Accuracy          : \", accuracy, \"\\n Balanced Accuracy : \", balanced_accuracy, \"\\n Precision         : \", precision, \"\\n Average Precision : \", average_precision, \"\\n F1-Score          : \", f1_score, \"\\n Recall            : \", recall, \"\\n ROC-AUC           : \", roc_auc, \"\\n\")\n",
    "\n",
    "print(metrics.classification_report(classes, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "{'priors': None, 'var_smoothing': 0.01} \n",
      "\n",
      "Model accuracy is 0.6859756097560976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "param_grid = [\n",
    "    {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "]\n",
    "\n",
    "gnb_bs_ff_rscv = RandomizedSearchCV(gnb_bs_ff, param_distributions = param_grid, cv = kfold, verbose=True, n_jobs=-1, random_state = 11)\n",
    "best_gnb_bs_ff_rscv = gnb_bs_ff_rscv.fit(X_train, y_train)\n",
    "\n",
    "print(best_gnb_bs_ff_rscv.best_estimator_.get_params(), '\\n')\n",
    "print('Model accuracy is',best_gnb_bs_ff_rscv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy          :  0.6859756097560976 \n",
      " Balanced Accuracy :  0.6696428571428572 \n",
      " Precision         :  0.8040201005025126 \n",
      " Average Precision :  0.7694220230070212 \n",
      " F1-Score          :  0.7565011820330969 \n",
      " Recall            :  0.7142857142857143 \n",
      " ROC-AUC           :  0.762377780374742 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.62      0.56       104\n",
      "         1.0       0.80      0.71      0.76       224\n",
      "\n",
      "    accuracy                           0.69       328\n",
      "   macro avg       0.65      0.67      0.66       328\n",
      "weighted avg       0.71      0.69      0.69       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "probs = best_gnb_bs_ff_rscv.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "classes = best_gnb_bs_ff_rscv.predict(X_test)\n",
    "    \n",
    "accuracy = metrics.accuracy_score(classes, y_test)\n",
    "    \n",
    "balanced_accuracy = metrics.balanced_accuracy_score(classes, y_test)\n",
    "\n",
    "precision = metrics.precision_score(classes, y_test)\n",
    "    \n",
    "average_precision = metrics.average_precision_score(classes, y_test)\n",
    "    \n",
    "f1_score = metrics.f1_score(classes, y_test)\n",
    "    \n",
    "recall = metrics.recall_score(classes, y_test)\n",
    "\n",
    "print (\"\\n Accuracy          : \", accuracy, \"\\n Balanced Accuracy : \", balanced_accuracy, \"\\n Precision         : \", precision, \"\\n Average Precision : \", average_precision, \"\\n F1-Score          : \", f1_score, \"\\n Recall            : \", recall, \"\\n ROC-AUC           : \", roc_auc, \"\\n\")\n",
    "\n",
    "print(metrics.classification_report(classes, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:02<00:00, 42.06trial/s, best loss: -0.6972081218274112]\n",
      "best:\n",
      "{'var_smoothing': 20}\n",
      "Accuracy :  69.72081218274113\n"
     ]
    }
   ],
   "source": [
    "def f(params):\n",
    "    acc = hyperopt_train_test(params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "def hyperopt_train_test(params):\n",
    "    gnb_bs_ff_bo = GaussianNB(**params)\n",
    "    return sklearn.model_selection.cross_val_score(gnb_bs_ff_bo, X_train, y_train).mean()\n",
    "\n",
    "param_grid = {\n",
    "    'var_smoothing': hp.choice('var_smoothing', np.logspace(0,-9, num=100))\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(f, param_grid, algo=tpe.suggest, max_evals=100, trials=trials)\n",
    "print('best:')\n",
    "print(best)\n",
    "print(\"Accuracy : \", -trials.best_trial['result']['loss']*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GP', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3P Made', '3PA', '3P%', 'FTM',\n",
       "       'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[['GP', '3P Made', '3PA', 'AST', 'BLK']]\n",
    "X_test = X_test[['GP', '3P Made', '3PA', 'AST', 'BLK']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = X_train.mean()\n",
    "train_std = X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>AST</th>\n",
       "      <th>BLK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.384826e-17</td>\n",
       "      <td>1.186043e-15</td>\n",
       "      <td>-1.324370e-15</td>\n",
       "      <td>6.514662e-16</td>\n",
       "      <td>-2.123866e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.845202e+00</td>\n",
       "      <td>-6.520126e-01</td>\n",
       "      <td>-7.413625e-01</td>\n",
       "      <td>-1.053552e+00</td>\n",
       "      <td>-9.190461e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.655035e-01</td>\n",
       "      <td>-6.520126e-01</td>\n",
       "      <td>-7.413625e-01</td>\n",
       "      <td>-6.398944e-01</td>\n",
       "      <td>-6.653027e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.010378e-01</td>\n",
       "      <td>-3.920530e-01</td>\n",
       "      <td>-4.586103e-01</td>\n",
       "      <td>-2.951796e-01</td>\n",
       "      <td>-4.115594e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.675790e-01</td>\n",
       "      <td>3.878260e-01</td>\n",
       "      <td>3.896464e-01</td>\n",
       "      <td>2.563641e-01</td>\n",
       "      <td>3.496707e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.256426e+00</td>\n",
       "      <td>4.807140e+00</td>\n",
       "      <td>4.065425e+00</td>\n",
       "      <td>5.358143e+00</td>\n",
       "      <td>5.932025e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 GP       3P Made           3PA           AST           BLK\n",
       "count  9.840000e+02  9.840000e+02  9.840000e+02  9.840000e+02  9.840000e+02\n",
       "mean   3.384826e-17  1.186043e-15 -1.324370e-15  6.514662e-16 -2.123866e-15\n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00\n",
       "min   -2.845202e+00 -6.520126e-01 -7.413625e-01 -1.053552e+00 -9.190461e-01\n",
       "25%   -7.655035e-01 -6.520126e-01 -7.413625e-01 -6.398944e-01 -6.653027e-01\n",
       "50%    1.010378e-01 -3.920530e-01 -4.586103e-01 -2.951796e-01 -4.115594e-01\n",
       "75%    9.675790e-01  3.878260e-01  3.896464e-01  2.563641e-01  3.496707e-01\n",
       "max    1.256426e+00  4.807140e+00  4.065425e+00  5.358143e+00  5.932025e+00"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = (X_test - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>AST</th>\n",
       "      <th>BLK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.018258</td>\n",
       "      <td>-0.056008</td>\n",
       "      <td>-0.056033</td>\n",
       "      <td>0.018637</td>\n",
       "      <td>-0.039454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.011584</td>\n",
       "      <td>0.905094</td>\n",
       "      <td>0.900421</td>\n",
       "      <td>0.958121</td>\n",
       "      <td>0.987205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.614125</td>\n",
       "      <td>-0.652013</td>\n",
       "      <td>-0.741363</td>\n",
       "      <td>-1.053552</td>\n",
       "      <td>-0.919046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.722176</td>\n",
       "      <td>-0.652013</td>\n",
       "      <td>-0.741363</td>\n",
       "      <td>-0.639894</td>\n",
       "      <td>-0.665303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.216577</td>\n",
       "      <td>-0.392053</td>\n",
       "      <td>-0.458610</td>\n",
       "      <td>-0.226237</td>\n",
       "      <td>-0.411559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.967579</td>\n",
       "      <td>0.127866</td>\n",
       "      <td>0.295396</td>\n",
       "      <td>0.342543</td>\n",
       "      <td>0.095927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.256426</td>\n",
       "      <td>4.287221</td>\n",
       "      <td>3.876924</td>\n",
       "      <td>4.599771</td>\n",
       "      <td>5.678281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               GP     3P Made         3PA         AST         BLK\n",
       "count  328.000000  328.000000  328.000000  328.000000  328.000000\n",
       "mean     0.018258   -0.056008   -0.056033    0.018637   -0.039454\n",
       "std      1.011584    0.905094    0.900421    0.958121    0.987205\n",
       "min     -2.614125   -0.652013   -0.741363   -1.053552   -0.919046\n",
       "25%     -0.722176   -0.652013   -0.741363   -0.639894   -0.665303\n",
       "50%      0.216577   -0.392053   -0.458610   -0.226237   -0.411559\n",
       "75%      0.967579    0.127866    0.295396    0.342543    0.095927\n",
       "max      1.256426    4.287221    3.876924    4.599771    5.678281"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - Naive Bayes Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 92  37]\n",
      " [ 54 145]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.71      0.67       129\n",
      "         1.0       0.80      0.73      0.76       199\n",
      "\n",
      "    accuracy                           0.72       328\n",
      "   macro avg       0.71      0.72      0.72       328\n",
      "weighted avg       0.73      0.72      0.72       328\n",
      "\n",
      "Score: \n",
      " 66.57\n",
      "Test Score: \n",
      " 72.26\n",
      "Accuracy: \n",
      " 0.7225609756097561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb_as_ff =  GaussianNB()\n",
    "gnb_as_ff.fit(X_train, y_train)\n",
    "y_pred = gnb_as_ff.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "gnb_as_ff_score = round(gnb_as_ff.score(X_train, y_train) * 100, 2)\n",
    "gnb_as_ff_score_test = round(gnb_as_ff.score(X_test, y_test) * 100, 2)\n",
    "print('Score: \\n', gnb_as_ff_score)\n",
    "print('Test Score: \\n', gnb_as_ff_score_test)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'priors': None, 'var_smoothing': 1.0} \n",
      "\n",
      "Model accuracy is 0.7012195121951219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "param_grid = [\n",
    "    {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "]\n",
    "\n",
    "gnb_as_ff_gscv = GridSearchCV(gnb_as_ff, param_grid = param_grid, cv = kfold, verbose=True, n_jobs=-1)\n",
    "best_gnb_as_ff_gscv = gnb_as_ff_gscv.fit(X_train, y_train)\n",
    "\n",
    "print(best_gnb_as_ff_gscv.best_estimator_.get_params(), '\\n')\n",
    "print('Model accuracy is',best_gnb_as_ff_gscv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy          :  0.7012195121951219 \n",
      " Balanced Accuracy :  0.6859394475493547 \n",
      " Precision         :  0.7788944723618091 \n",
      " Average Precision :  0.742283156944719 \n",
      " F1-Score          :  0.7598039215686274 \n",
      " Recall            :  0.7416267942583732 \n",
      " ROC-AUC           :  0.7646371391842935 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.63      0.60       119\n",
      "         1.0       0.78      0.74      0.76       209\n",
      "\n",
      "    accuracy                           0.70       328\n",
      "   macro avg       0.68      0.69      0.68       328\n",
      "weighted avg       0.71      0.70      0.70       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "probs = best_gnb_as_ff_gscv.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "classes = best_gnb_as_ff_gscv.predict(X_test)\n",
    "    \n",
    "accuracy = metrics.accuracy_score(classes, y_test)\n",
    "    \n",
    "balanced_accuracy = metrics.balanced_accuracy_score(classes, y_test)\n",
    "\n",
    "precision = metrics.precision_score(classes, y_test)\n",
    "    \n",
    "average_precision = metrics.average_precision_score(classes, y_test)\n",
    "    \n",
    "f1_score = metrics.f1_score(classes, y_test)\n",
    "    \n",
    "recall = metrics.recall_score(classes, y_test)\n",
    "\n",
    "print (\"\\n Accuracy          : \", accuracy, \"\\n Balanced Accuracy : \", balanced_accuracy, \"\\n Precision         : \", precision, \"\\n Average Precision : \", average_precision, \"\\n F1-Score          : \", f1_score, \"\\n Recall            : \", recall, \"\\n ROC-AUC           : \", roc_auc, \"\\n\")\n",
    "\n",
    "print(metrics.classification_report(classes, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "{'priors': None, 'var_smoothing': 6.579332246575683e-05} \n",
      "\n",
      "Model accuracy is 0.7225609756097561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "param_grid = [\n",
    "    {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "]\n",
    "\n",
    "gnb_as_ff_rscv = RandomizedSearchCV(gnb_as_ff, param_distributions = param_grid, cv = kfold, verbose=True, n_jobs=-1, random_state = 11)\n",
    "best_gnb_as_ff_rscv = gnb_as_ff_rscv.fit(X_train, y_train)\n",
    "\n",
    "print(best_gnb_as_ff_rscv.best_estimator_.get_params(), '\\n')\n",
    "print('Model accuracy is',best_gnb_as_ff_rscv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy          :  0.7225609756097561 \n",
      " Balanced Accuracy :  0.7134201415023332 \n",
      " Precision         :  0.7286432160804021 \n",
      " Average Precision :  0.6933173304205293 \n",
      " F1-Score          :  0.7611548556430446 \n",
      " Recall            :  0.7967032967032966 \n",
      " ROC-AUC           :  0.7573137002843675 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.63      0.67       146\n",
      "         1.0       0.73      0.80      0.76       182\n",
      "\n",
      "    accuracy                           0.72       328\n",
      "   macro avg       0.72      0.71      0.72       328\n",
      "weighted avg       0.72      0.72      0.72       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "probs = best_gnb_as_ff_rscv.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "classes = best_gnb_as_ff_rscv.predict(X_test)\n",
    "    \n",
    "accuracy = metrics.accuracy_score(classes, y_test)\n",
    "    \n",
    "balanced_accuracy = metrics.balanced_accuracy_score(classes, y_test)\n",
    "\n",
    "precision = metrics.precision_score(classes, y_test)\n",
    "    \n",
    "average_precision = metrics.average_precision_score(classes, y_test)\n",
    "    \n",
    "f1_score = metrics.f1_score(classes, y_test)\n",
    "    \n",
    "recall = metrics.recall_score(classes, y_test)\n",
    "\n",
    "print (\"\\n Accuracy          : \", accuracy, \"\\n Balanced Accuracy : \", balanced_accuracy, \"\\n Precision         : \", precision, \"\\n Average Precision : \", average_precision, \"\\n F1-Score          : \", f1_score, \"\\n Recall            : \", recall, \"\\n ROC-AUC           : \", roc_auc, \"\\n\")\n",
    "\n",
    "print(metrics.classification_report(classes, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:02<00:00, 44.12trial/s, best loss: -0.6880089091474153]\n",
      "best:\n",
      "{'var_smoothing': 0}\n",
      "Accuracy :  68.80089091474153\n"
     ]
    }
   ],
   "source": [
    "def f(params):\n",
    "    acc = hyperopt_train_test(params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "def hyperopt_train_test(params):\n",
    "    gnb_as_ff_bo = GaussianNB(**params)\n",
    "    return sklearn.model_selection.cross_val_score(gnb_as_ff_bo, X_train, y_train).mean()\n",
    "\n",
    "param_grid = {\n",
    "    'var_smoothing': hp.choice('var_smoothing', np.logspace(0,-9, num=100))\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(f, param_grid, algo=tpe.suggest, max_evals=100, trials=trials)\n",
    "print('best:')\n",
    "print(best)\n",
    "print(\"Accuracy : \", -trials.best_trial['result']['loss']*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Better performing models from the fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GP', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3P Made', '3PA', '3P%', 'FTM',\n",
       "       'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[['GP', '3P Made', '3PA', 'AST', 'BLK']]\n",
    "X_test = X_test[['GP', '3P Made', '3PA', 'AST', 'BLK']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = X_train.mean()\n",
    "train_std = X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>AST</th>\n",
       "      <th>BLK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.384826e-17</td>\n",
       "      <td>1.186043e-15</td>\n",
       "      <td>-1.324370e-15</td>\n",
       "      <td>6.514662e-16</td>\n",
       "      <td>-2.123866e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.845202e+00</td>\n",
       "      <td>-6.520126e-01</td>\n",
       "      <td>-7.413625e-01</td>\n",
       "      <td>-1.053552e+00</td>\n",
       "      <td>-9.190461e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.655035e-01</td>\n",
       "      <td>-6.520126e-01</td>\n",
       "      <td>-7.413625e-01</td>\n",
       "      <td>-6.398944e-01</td>\n",
       "      <td>-6.653027e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.010378e-01</td>\n",
       "      <td>-3.920530e-01</td>\n",
       "      <td>-4.586103e-01</td>\n",
       "      <td>-2.951796e-01</td>\n",
       "      <td>-4.115594e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.675790e-01</td>\n",
       "      <td>3.878260e-01</td>\n",
       "      <td>3.896464e-01</td>\n",
       "      <td>2.563641e-01</td>\n",
       "      <td>3.496707e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.256426e+00</td>\n",
       "      <td>4.807140e+00</td>\n",
       "      <td>4.065425e+00</td>\n",
       "      <td>5.358143e+00</td>\n",
       "      <td>5.932025e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 GP       3P Made           3PA           AST           BLK\n",
       "count  9.840000e+02  9.840000e+02  9.840000e+02  9.840000e+02  9.840000e+02\n",
       "mean   3.384826e-17  1.186043e-15 -1.324370e-15  6.514662e-16 -2.123866e-15\n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00\n",
       "min   -2.845202e+00 -6.520126e-01 -7.413625e-01 -1.053552e+00 -9.190461e-01\n",
       "25%   -7.655035e-01 -6.520126e-01 -7.413625e-01 -6.398944e-01 -6.653027e-01\n",
       "50%    1.010378e-01 -3.920530e-01 -4.586103e-01 -2.951796e-01 -4.115594e-01\n",
       "75%    9.675790e-01  3.878260e-01  3.896464e-01  2.563641e-01  3.496707e-01\n",
       "max    1.256426e+00  4.807140e+00  4.065425e+00  5.358143e+00  5.932025e+00"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = (X_test - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>AST</th>\n",
       "      <th>BLK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.018258</td>\n",
       "      <td>-0.056008</td>\n",
       "      <td>-0.056033</td>\n",
       "      <td>0.018637</td>\n",
       "      <td>-0.039454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.011584</td>\n",
       "      <td>0.905094</td>\n",
       "      <td>0.900421</td>\n",
       "      <td>0.958121</td>\n",
       "      <td>0.987205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.614125</td>\n",
       "      <td>-0.652013</td>\n",
       "      <td>-0.741363</td>\n",
       "      <td>-1.053552</td>\n",
       "      <td>-0.919046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.722176</td>\n",
       "      <td>-0.652013</td>\n",
       "      <td>-0.741363</td>\n",
       "      <td>-0.639894</td>\n",
       "      <td>-0.665303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.216577</td>\n",
       "      <td>-0.392053</td>\n",
       "      <td>-0.458610</td>\n",
       "      <td>-0.226237</td>\n",
       "      <td>-0.411559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.967579</td>\n",
       "      <td>0.127866</td>\n",
       "      <td>0.295396</td>\n",
       "      <td>0.342543</td>\n",
       "      <td>0.095927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.256426</td>\n",
       "      <td>4.287221</td>\n",
       "      <td>3.876924</td>\n",
       "      <td>4.599771</td>\n",
       "      <td>5.678281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               GP     3P Made         3PA         AST         BLK\n",
       "count  328.000000  328.000000  328.000000  328.000000  328.000000\n",
       "mean     0.018258   -0.056008   -0.056033    0.018637   -0.039454\n",
       "std      1.011584    0.905094    0.900421    0.958121    0.987205\n",
       "min     -2.614125   -0.652013   -0.741363   -1.053552   -0.919046\n",
       "25%     -0.722176   -0.652013   -0.741363   -0.639894   -0.665303\n",
       "50%      0.216577   -0.392053   -0.458610   -0.226237   -0.411559\n",
       "75%      0.967579    0.127866    0.295396    0.342543    0.095927\n",
       "max      1.256426    4.287221    3.876924    4.599771    5.678281"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - SGD (Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 92  37]\n",
      " [ 54 145]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.71      0.67       129\n",
      "         1.0       0.80      0.73      0.76       199\n",
      "\n",
      "    accuracy                           0.72       328\n",
      "   macro avg       0.71      0.72      0.72       328\n",
      "weighted avg       0.73      0.72      0.72       328\n",
      "\n",
      "Score: \n",
      " 67.68\n",
      "Test Score: \n",
      " 72.26\n",
      "Accuracy: \n",
      " 0.7225609756097561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_as_ff =  SGDClassifier(random_state = 11)\n",
    "sgd_as_ff.fit(X_train, y_train)\n",
    "y_pred = sgd_as_ff.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "sgd_as_ff_score = round(sgd_as_ff.score(X_train, y_train) * 100, 2)\n",
    "sgd_as_ff_score_test = round(sgd_as_ff.score(X_test, y_test) * 100, 2)\n",
    "print('Score: \\n', sgd_as_ff_score)\n",
    "print('Test Score: \\n', sgd_as_ff_score_test)\n",
    "print('Accuracy: \\n', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1830 tasks      | elapsed:    8.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'log', 'max_iter': 1000, 'n_iter_no_change': 100, 'n_jobs': None, 'penalty': 'l1', 'power_t': 0.5, 'random_state': 11, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False} \n",
      "\n",
      "Model accuracy is 0.6951219512195121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:    9.4s finished\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "param_grid = [\n",
    "    {'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3], \n",
    "    'n_iter_no_change': [1, 5, 10, 100, 1000], \n",
    "    'loss' : ['hinge', 'log', 'modified_huber', 'squared_hinge',  'perceptron'],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    #'learning_rate' : ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "    #'eta0' : ['eta0']\n",
    "    }\n",
    "]\n",
    "\n",
    "sgd_as_ff_gscv = GridSearchCV(sgd_as_ff, param_grid = param_grid, cv = kfold, verbose=True, n_jobs=-1)\n",
    "best_sgd_as_ff_gscv = sgd_as_ff_gscv.fit(X_train, y_train)\n",
    "\n",
    "print(best_sgd_as_ff_gscv.best_estimator_.get_params(), '\\n')\n",
    "print('Model accuracy is',best_sgd_as_ff_gscv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy          :  0.6951219512195121 \n",
      " Balanced Accuracy :  0.6818851251840943 \n",
      " Precision         :  0.8291457286432161 \n",
      " Average Precision :  0.7934664612259906 \n",
      " F1-Score          :  0.7674418604651164 \n",
      " Recall            :  0.7142857142857143 \n",
      " ROC-AUC           :  0.7789334268240427 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.65      0.56        97\n",
      "         1.0       0.83      0.71      0.77       231\n",
      "\n",
      "    accuracy                           0.70       328\n",
      "   macro avg       0.66      0.68      0.66       328\n",
      "weighted avg       0.73      0.70      0.71       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "probs = best_sgd_as_ff_gscv.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "classes = best_sgd_as_ff_gscv.predict(X_test)\n",
    "    \n",
    "accuracy = metrics.accuracy_score(classes, y_test)\n",
    "    \n",
    "balanced_accuracy = metrics.balanced_accuracy_score(classes, y_test)\n",
    "\n",
    "precision = metrics.precision_score(classes, y_test)\n",
    "    \n",
    "average_precision = metrics.average_precision_score(classes, y_test)\n",
    "    \n",
    "f1_score = metrics.f1_score(classes, y_test)\n",
    "    \n",
    "recall = metrics.recall_score(classes, y_test)\n",
    "\n",
    "print (\"\\n Accuracy          : \", accuracy, \"\\n Balanced Accuracy : \", balanced_accuracy, \"\\n Precision         : \", precision, \"\\n Average Precision : \", average_precision, \"\\n F1-Score          : \", f1_score, \"\\n Recall            : \", recall, \"\\n ROC-AUC           : \", roc_auc, \"\\n\")\n",
    "\n",
    "print(metrics.classification_report(classes, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "{'alpha': 0.01, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'modified_huber', 'max_iter': 1000, 'n_iter_no_change': 10, 'n_jobs': None, 'penalty': 'l1', 'power_t': 0.5, 'random_state': 11, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False} \n",
      "\n",
      "Model accuracy is 0.6890243902439024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "param_grid = [\n",
    "    {'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3], \n",
    "    'n_iter_no_change': [1, 5, 10, 100, 1000], \n",
    "    'loss' : ['hinge', 'log', 'modified_huber', 'squared_hinge',  'perceptron'],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    #'learning_rate' : ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "    #'eta0' : ['eta0']\n",
    "    }\n",
    "]\n",
    "\n",
    "sgd_as_ff_rscv = RandomizedSearchCV(sgd_as_ff, param_distributions = param_grid, cv = kfold, verbose=True, n_jobs=-1, random_state = 11)\n",
    "best_sgd_as_ff_rscv = sgd_as_ff_rscv.fit(X_train, y_train)\n",
    "\n",
    "print(best_sgd_as_ff_rscv.best_estimator_.get_params(), '\\n')\n",
    "print('Model accuracy is',best_sgd_as_ff_rscv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy          :  0.6890243902439024 \n",
      " Balanced Accuracy :  0.6729348824210484 \n",
      " Precision         :  0.7638190954773869 \n",
      " Average Precision :  0.7285549196435814 \n",
      " F1-Score          :  0.748768472906404 \n",
      " Recall            :  0.7342995169082126 \n",
      " ROC-AUC           :  0.7719605780842195 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.61      0.59       121\n",
      "         1.0       0.76      0.73      0.75       207\n",
      "\n",
      "    accuracy                           0.69       328\n",
      "   macro avg       0.67      0.67      0.67       328\n",
      "weighted avg       0.69      0.69      0.69       328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "probs = best_sgd_as_ff_rscv.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "classes = best_sgd_as_ff_rscv.predict(X_test)\n",
    "    \n",
    "accuracy = metrics.accuracy_score(classes, y_test)\n",
    "    \n",
    "balanced_accuracy = metrics.balanced_accuracy_score(classes, y_test)\n",
    "\n",
    "precision = metrics.precision_score(classes, y_test)\n",
    "    \n",
    "average_precision = metrics.average_precision_score(classes, y_test)\n",
    "    \n",
    "f1_score = metrics.f1_score(classes, y_test)\n",
    "    \n",
    "recall = metrics.recall_score(classes, y_test)\n",
    "\n",
    "print (\"\\n Accuracy          : \", accuracy, \"\\n Balanced Accuracy : \", balanced_accuracy, \"\\n Precision         : \", precision, \"\\n Average Precision : \", average_precision, \"\\n F1-Score          : \", f1_score, \"\\n Recall            : \", recall, \"\\n ROC-AUC           : \", roc_auc, \"\\n\")\n",
    "\n",
    "print(metrics.classification_report(classes, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:08<00:00, 12.29trial/s, best loss: -0.7032839531751787]\n",
      "best:\n",
      "{'alpha': 0, 'loss': 0, 'n_iter_no_change': 3, 'penalty': 0}\n",
      "Accuracy :  70.32839531751787\n"
     ]
    }
   ],
   "source": [
    "def f(params):\n",
    "    acc = hyperopt_train_test(params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "def hyperopt_train_test(params):\n",
    "    sgd_as_ff_bo = SGDClassifier(**params)\n",
    "    return sklearn.model_selection.cross_val_score(sgd_as_ff_bo, X_train, y_train).mean()\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': hp.choice('alpha', [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]),\n",
    "    'n_iter_no_change' : hp.choice('n_iter_no_change', [1, 5, 10, 100, 1000]),\n",
    "    'loss' : hp.choice('loss', ['hinge', 'log', 'modified_huber', 'squared_hinge',  'perceptron']),\n",
    "    'penalty' : hp.choice('penalty', ['l1', 'l2'])\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(f, param_grid, algo=tpe.suggest, max_evals=100, trials=trials)\n",
    "print('best:')\n",
    "print(best)\n",
    "print(\"Accuracy : \", -trials.best_trial['result']['loss']*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling - Combining Two Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W9Cx5MAoKGUH",
    "outputId": "7b7d6894-61e9-4bf7-810a-76c695cdc28e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "from mlens.ensemble import SuperLearner\n",
    "from mlens.model_selection import Evaluator\n",
    "from mlens.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=2,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=4782, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=2, raise_on_ex...C22B438>)],\n",
       "   n_jobs=-1, name='group-1', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=555, sample_size=20,\n",
       "       scorer=<function accuracy_score at 0x000001C93C22B438>,\n",
       "       shuffle=False, verbose=2)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble = SuperLearner(scorer=accuracy_score, random_state=555, verbose=2)\n",
    "ensemble.add([lr_as_af, sgd_as_ff])\n",
    "ensemble.add_meta(GaussianNB())\n",
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "Accuracy - Train :  0.6839430894308943\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "Accuracy - Test :  0.7225609756097561\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy - Train : \", sklearn.metrics.accuracy_score(ensemble.predict(X_train), y_train))\n",
    "print (\"Accuracy - Test : \", sklearn.metrics.accuracy_score(ensemble.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit data:\n",
      "                               score-m  score-s  ft-m  ft-s  pt-m  pt-s\n",
      "layer-1  logisticregression       0.70     0.02  0.02  0.00  0.00  0.00\n",
      "layer-1  sgdclassifier            0.69     0.01  0.02  0.00  0.00  0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit data:\\n%r\" % ensemble.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
